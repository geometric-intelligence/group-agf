# ============================================================================
# Base Configuration File
# ============================================================================
# This config supports various group tasks with either QuadraticRNN or
# SequentialMLP models.
#
# Quick Setup Guide:
# ------------------
# Cyclic group C_p:        Set group_name='cn', specify p
# Product group C_p1xC_p2: Set group_name='cnxcn', specify p1 and p2
# Dihedral group D_n:      Set group_name='dihedral', specify group_n
# Octahedral group:        Set group_name='octahedral'
# Icosahedral (A5):        Set group_name='A5'
# QuadraticRNN:            Set model_type='QuadraticRNN'
# SequentialMLP:           Set model_type='SequentialMLP'
# ============================================================================

# Data Configuration
# ------------------
data:
  # Group name: 'cn' | 'cnxcn' | 'dihedral' | 'octahedral' | 'A5'
  group_name: dihedral

  # Group order parameter (for parameterized groups)
  # For dihedral: n in D_n (e.g., 3 for D3, 4 for D4)
  group_n: 3

  # Group Parameters
  # For group_name='cn': only 'p' is used
  # For group_name='cnxcn': 'p1' and 'p2' are used
  # For group_name='dihedral'/'octahedral'/'A5': p, p1, p2 are not used
  p: 10        # Cyclic group dimension (cn only)

  p1: 4 #10       # Height/rows dimension (2D only)
  p2: 4        # Width/cols dimension (2D only)

  k: 5          # Sequence length
  batch_size: 1000
  seed: 5

  # Template Generation
  # For group_name='cn','cnxcn': 'mnist' | 'fourier' | 'gaussian' | 'onehot'
  # For group_name='dihedral','octahedral','A5': 'onehot' | 'custom_fourier'
  template_type: onehot
  mnist_label: 4            # MNIST digit (0-9), only if template_type='mnist'
  n_freqs: 1               # Number of Fourier modes, only if template_type='fourier'

  # custom_fourier template: powers for each irrep's Fourier coefficient
  # Example for D3: 3 irreps with dimensions [1, 1, 2], so powers should have 3 values
  # Large ratio between powers = clearer staircase steps
  powers:
  - 0.0
  - 2000.0
  - 400.0

  # Dataset Mode (offline training only)
  mode: exhaustive             # 'sampled' | 'exhaustive'
  num_samples: 1000

# Model Configuration
# -------------------
model:
  model_type: SequentialMLP  # 'QuadraticRNN' | 'SequentialMLP'

  hidden_dim: 600              # Hidden layer size
                              # Note: SequentialMLP may need larger values (e.g., 600)

  init_scale: 4.5e-3          # Weight initialization scale
                              # Larger k may need larger init_scale

  return_all_outputs: false   # true = seq-to-seq guidance (for QuadraticRNN only)
                              # false = seq-to-one (final output only)

  transform_type: quadratic # 'quadratic' | 'multiplicative'
                              # Only used for QuadraticRNN

# Training Configuration
# ----------------------
training:
  mode: offline              # 'online' | 'offline'

  # Steps/Epochs
  epochs: 2 #10000                  # Used when mode='offline'
  num_steps: 100                # Used when mode='online'

  # Optimizer
  optimizer: adam       # 'auto' | 'adam' | 'hybrid' | 'per_neuron'
                              # 'auto' selects optimizer based on model:
                              #   - SequentialMLP → 'per_neuron' (recommended)
                              #   - QuadraticRNN → 'adam'
                              # 'hybrid' is QuadraticRNN-specific only

  learning_rate: 0.00008        # Base learning rate
                              # Recommended settings:
                              #   - adam: 1e-3 to 1e-4
                              #   - per_neuron (SequentialMLP): 1.0 (or 0.01 for dihedral)
                              #   - hybrid: see scaling_factor

  betas:
  - 0.9
  - 0.999         # Adam/hybrid beta parameters
  weight_decay: 0.0

  # Homogeneity-based scaling parameters
  scaling_factor: -3          # For 'hybrid' optimizer only (QuadraticRNN)
  degree: null                # For 'per_neuron' optimizer: degree of homogeneity
                              # If null (default), auto-inferred from model:
                              #   - SequentialMLP: uses k+1 (k = sequence length)
                              #   - Other models: defaults to 2

  # Training Dynamics
  grad_clip: 0.1
  verbose_interval: 1000
  save_param_interval: 10      # Save params every N steps/epochs
                              # Set to null to only save initial & final (memory efficient for sweeps)

  # Early Stopping (optional)
  # -------------------------
  # Stop training early when loss reduction reaches a threshold.
  # Set to null to disable (train for full num_steps/epochs).
  reduction_threshold: null   # e.g., 0.99 = stop when 99% loss reduction achieved
                              # null = disabled (train for full steps/epochs)

# Device
# ------
device: cuda:1                  # 'cuda' | 'cpu'

# Analysis & Visualization
# ------------------------
analysis:
  checkpoints:
  - 0.0
  - 1.0  # Fraction of training for analysis
