{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "def load_sweep_results_grid(sweep_dir: str, k_values: list, hidden_dims: list):\n",
    "    \"\"\"\n",
    "    Load sweep results and organize into a grid for heatmap visualization.\n",
    "    \n",
    "    Args:\n",
    "        sweep_dir: Path to the sweep directory\n",
    "        k_values: List of k (sequence length) values\n",
    "        hidden_dims: List of hidden dimension values\n",
    "        \n",
    "    Returns:\n",
    "        grid: 2D numpy array with shape (len(hidden_dims), len(k_values))\n",
    "              containing mean final train losses\n",
    "        std_grid: 2D numpy array with standard deviations (if multiple seeds)\n",
    "    \"\"\"\n",
    "    sweep_path = Path(sweep_dir)\n",
    "    \n",
    "    # Initialize grids\n",
    "    grid = np.full((len(hidden_dims), len(k_values)), np.nan)\n",
    "    std_grid = np.full((len(hidden_dims), len(k_values)), np.nan)\n",
    "    \n",
    "    # Load results for each experiment\n",
    "    for i, h in enumerate(hidden_dims):\n",
    "        for j, k in enumerate(k_values):\n",
    "            exp_name = f\"k{k}_h{h}\"\n",
    "            exp_dir = sweep_path / exp_name\n",
    "            \n",
    "            if not exp_dir.exists():\n",
    "                print(f\"Warning: Experiment {exp_name} not found\")\n",
    "                continue\n",
    "            \n",
    "            # Load experiment summary\n",
    "            summary_file = exp_dir / \"experiment_summary.yaml\"\n",
    "            if summary_file.exists():\n",
    "                with open(summary_file, 'r') as f:\n",
    "                    summary = yaml.safe_load(f)\n",
    "                \n",
    "                # Get mean train loss\n",
    "                if 'train_loss_stats' in summary:\n",
    "                    grid[i, j] = summary['train_loss_stats']['mean']\n",
    "                    std_grid[i, j] = summary['train_loss_stats']['std']\n",
    "                else:\n",
    "                    print(f\"Warning: No train_loss_stats in {exp_name}\")\n",
    "            else:\n",
    "                print(f\"Warning: No summary file for {exp_name}\")\n",
    "    \n",
    "    return grid, std_grid\n"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "af291059"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Analysis Functions\n",
    "\n",
    "Analyze individual 1D experiments from the sweep with detailed power spectrum and neuron specialization plots.\n"
   ],
   "id": "c433cb4d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from gagf.rnns.utils import (\n",
    "    plot_prediction_power_spectrum_over_time_1d,\n",
    "    plot_wout_neuron_specialization_1d,\n",
    "    plot_model_predictions_over_time_1d,\n",
    "    topk_template_freqs_1d,\n",
    ")\n",
    "from gagf.rnns.model import SequentialMLP\n",
    "\n",
    "def analyze_1d_experiment(sweep_dir, exp_name, seed=0, num_freqs_to_track=10):\n",
    "    \"\"\"\n",
    "    Analyze a single 1D experiment from the sweep.\n",
    "    \n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        exp_name: Experiment name (e.g., \"k3_h360\")\n",
    "        seed: Seed number to analyze\n",
    "        num_freqs_to_track: Number of top frequencies to track\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    # Setup paths\n",
    "    sweep_path = Path(sweep_dir)\n",
    "    exp_dir = sweep_path / exp_name / f\"seed_{seed}\"\n",
    "    \n",
    "    if not exp_dir.exists():\n",
    "        print(f\"Experiment directory not found: {exp_dir}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Analyzing: {exp_name}, seed {seed}\")\n",
    "    print(f\"Directory: {exp_dir}\")\n",
    "    \n",
    "    # Load config\n",
    "    with open(exp_dir / \"config.yaml\", 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Load template\n",
    "    template = np.load(exp_dir / \"template.npy\")\n",
    "    p = len(template)\n",
    "    k = config['data']['k']\n",
    "    hidden_dim = config['model']['hidden_dim']\n",
    "    \n",
    "    print(f\"  p={p}, k={k}, hidden_dim={hidden_dim}\")\n",
    "    \n",
    "    # Load training history\n",
    "    train_loss_hist = np.load(exp_dir / \"train_loss_history.npy\")\n",
    "    param_hist = torch.load(exp_dir / \"param_history.pt\", map_location='cpu')\n",
    "    \n",
    "    # Create model\n",
    "    device = 'cpu'\n",
    "    template_torch = torch.tensor(template, dtype=torch.float32, device=device)\n",
    "    model = SequentialMLP(\n",
    "        p=p,\n",
    "        d=hidden_dim,\n",
    "        template=template_torch,\n",
    "        k=k,\n",
    "        init_scale=config['model']['init_scale'],\n",
    "        return_all_outputs=config['model']['return_all_outputs'],\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate evaluation data\n",
    "    from gagf.rnns.datamodule import build_modular_addition_sequence_dataset_1d\n",
    "    X_data, Y_data, _ = build_modular_addition_sequence_dataset_1d(\n",
    "        p, template, k,\n",
    "        mode='sampled',\n",
    "        num_samples=1000,\n",
    "        return_all_outputs=config['model']['return_all_outputs'],\n",
    "    )\n",
    "    X_data_t = torch.tensor(X_data, dtype=torch.float32, device=device)\n",
    "    Y_data_t = torch.tensor(Y_data, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Get tracked frequencies\n",
    "    tracked_freqs = topk_template_freqs_1d(template, K=num_freqs_to_track)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(tracked_freqs)))\n",
    "    \n",
    "    # Checkpoints to analyze\n",
    "    checkpoint_indices = [0, len(param_hist)//4, len(param_hist)//2, \n",
    "                          3*len(param_hist)//4, len(param_hist)-1]\n",
    "    \n",
    "    # Plot 1: Power spectrum over time\n",
    "    print(\"\\\\n  Plotting power spectrum analysis...\")\n",
    "    fig1, _, _, _ = plot_prediction_power_spectrum_over_time_1d(\n",
    "        model, param_hist, X_data_t, Y_data_t, template, p,\n",
    "        loss_history=train_loss_hist,\n",
    "        num_freqs_to_track=num_freqs_to_track,\n",
    "        num_samples=100,\n",
    "        save_path=exp_dir / \"power_spectrum_analysis_1d.pdf\",\n",
    "        show=True\n",
    "    )\n",
    "    \n",
    "    # Plot 2: Model predictions over time\n",
    "    print(\"  Plotting predictions over time...\")\n",
    "    fig2, _ = plot_model_predictions_over_time_1d(\n",
    "        model, param_hist, X_data_t, Y_data_t, p,\n",
    "        steps=checkpoint_indices,\n",
    "        save_path=exp_dir / \"predictions_over_time_1d.pdf\",\n",
    "        show=True\n",
    "    )\n",
    "    \n",
    "    # Plot 3: W_out neuron specialization\n",
    "    print(\"  Plotting W_out neuron specialization...\")\n",
    "    figs3 = plot_wout_neuron_specialization_1d(\n",
    "        param_hist, tracked_freqs, colors, p,\n",
    "        steps=checkpoint_indices,\n",
    "        dead_thresh_l2=0.25,\n",
    "        save_dir=exp_dir,\n",
    "        show=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\n  \u2713 Analysis complete!\")\n",
    "    \n",
    "    return {\n",
    "        'config': config,\n",
    "        'template': template,\n",
    "        'train_loss': train_loss_hist,\n",
    "        'tracked_freqs': tracked_freqs,\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# sweep_dir = \"/home/facosta/group-agf/sweeps/sweep_mlp_scaling_20251202_XXXXXX\"\n",
    "# result = analyze_1d_experiment(sweep_dir, \"k3_h360\", seed=0)\n"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "95df6861"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze RNNs trained on GAGF sequential task"
   ],
   "id": "7bc3db90"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ],
   "id": "11fb7c9b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# jupyter black formatter\n",
    "%load_ext jupyter_black\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "gitroot_path = subprocess.check_output(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], universal_newlines=True\n",
    ").strip()\n",
    "\n",
    "os.chdir(gitroot_path)\n",
    "print(\"Working directory: \", os.getcwd())\n",
    "\n",
    "if gitroot_path not in sys.path:\n",
    "    sys.path.insert(0, gitroot_path)\n",
    "print(\"Directory added to path: \", gitroot_path)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "43581ce4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence sweep across different values of k (sequence length)"
   ],
   "id": "f0407a17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss curves"
   ],
   "id": "070e8c55"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "\n",
    "def get_sweep_experiments(sweep_dir: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get all experiment names from a sweep directory.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "\n",
    "    Returns:\n",
    "        List of experiment names (subdirectories with seed_0)\n",
    "    \"\"\"\n",
    "    sweep_path = Path(sweep_dir)\n",
    "    experiments = []\n",
    "\n",
    "    for item in sweep_path.iterdir():\n",
    "        if (\n",
    "            item.is_dir()\n",
    "            and not item.name.startswith(\".\")\n",
    "            and item.name not in [\"configs\"]\n",
    "        ):\n",
    "            # Check if it has a seed_0 subdirectory\n",
    "            if (item / \"seed_0\").exists():\n",
    "                experiments.append(item.name)\n",
    "\n",
    "    return sorted(experiments)\n",
    "\n",
    "\n",
    "def load_experiment_losses(\n",
    "    sweep_dir: str, experiment_name: str, seed: int = 0\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load training and validation loss histories for an experiment.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        experiment_name: Name of the experiment subdirectory\n",
    "        seed: Seed number (default: 0)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with 'train' and 'val' loss arrays (if they exist)\n",
    "    \"\"\"\n",
    "    exp_path = Path(sweep_dir) / experiment_name / f\"seed_{seed}\"\n",
    "    losses = {}\n",
    "\n",
    "    train_loss_path = exp_path / \"train_loss_history.npy\"\n",
    "    if train_loss_path.exists():\n",
    "        losses[\"train\"] = np.load(train_loss_path)\n",
    "\n",
    "    val_loss_path = exp_path / \"val_loss_history.npy\"\n",
    "    if val_loss_path.exists():\n",
    "        losses[\"val\"] = np.load(val_loss_path)\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def load_all_sweep_losses(\n",
    "    sweep_dir: str, seed: int = 0\n",
    ") -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Load loss histories for all experiments in a sweep.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        seed: Seed number (default: 0)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping experiment names to their loss dictionaries\n",
    "    \"\"\"\n",
    "    experiments = get_sweep_experiments(sweep_dir)\n",
    "    all_losses = {}\n",
    "\n",
    "    for exp_name in experiments:\n",
    "        all_losses[exp_name] = load_experiment_losses(sweep_dir, exp_name, seed)\n",
    "\n",
    "    return all_losses\n",
    "\n",
    "\n",
    "def remove_outliers_local(loss_history, window=10, threshold=3.0):\n",
    "    \"\"\"\n",
    "    Replace outliers with local median if they deviate too much.\n",
    "\n",
    "    Args:\n",
    "        loss_history: Array of loss values\n",
    "        window: Window size for local statistics\n",
    "        threshold: How many local standard deviations to consider an outlier\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (cleaned loss history, whether any outliers were found)\n",
    "    \"\"\"\n",
    "    cleaned = loss_history.copy()\n",
    "    half_window = window // 2\n",
    "    outliers_found = False\n",
    "\n",
    "    for i in range(len(loss_history)):\n",
    "        start = max(0, i - half_window)\n",
    "        end = min(len(loss_history), i + half_window + 1)\n",
    "        local_window = loss_history[start:end]\n",
    "\n",
    "        local_median = np.median(local_window)\n",
    "        local_std = np.std(local_window)\n",
    "\n",
    "        # If the value is too far from local median, replace it\n",
    "        if abs(loss_history[i] - local_median) > threshold * local_std:\n",
    "            cleaned[i] = local_median\n",
    "            outliers_found = True\n",
    "\n",
    "    return cleaned, outliers_found"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "cf050abb"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set up your sweep directory\n",
    "sweep_dir = \"/home/facosta/group-agf/sweeps/seq_seq_sweep_20251113_120513\"\n",
    "\n",
    "# Get all experiments in the sweep\n",
    "experiments = get_sweep_experiments(sweep_dir)\n",
    "print(f\"Found experiments: {experiments}\")\n",
    "\n",
    "# Load losses for all experiments\n",
    "all_losses = load_all_sweep_losses(sweep_dir)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "6b5653c8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_loss_comparison(\n",
    "    sweep_dir: str,\n",
    "    experiments: Optional[List[str]] = None,\n",
    "    loss_type: str = \"train\",\n",
    "    log_scale: bool = True,\n",
    "    figsize: tuple = (10, 6),\n",
    "    seed: int = 0,\n",
    "    remove_outliers: bool = False,\n",
    "    outlier_window: int = 10,\n",
    "    outlier_threshold: float = 3.0,\n",
    "    template_2d: Optional[np.ndarray] = None,\n",
    "    p1: Optional[int] = None,\n",
    "    p2: Optional[int] = None,\n",
    "    show_theory_bands: bool = True,\n",
    "    num_theory_lines: Optional[int] = None,\n",
    "    color_by_k: bool = True,\n",
    "    cmap: str = \"viridis\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot and compare loss curves from multiple experiments.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        experiments: List of experiment names to plot (None = all experiments)\n",
    "        loss_type: 'train' or 'val'\n",
    "        log_scale: Whether to use log scale for both axes\n",
    "        figsize: Figure size tuple\n",
    "        seed: Seed number (default: 0)\n",
    "        remove_outliers: Whether to remove outliers using local outlier replacement\n",
    "        outlier_window: Window size for outlier detection (default: 10)\n",
    "        outlier_threshold: Threshold in standard deviations for outlier detection (default: 3.0)\n",
    "        template_2d: Optional 2D template array for computing theory lines\n",
    "        p1: First dimension of template (required if template_2d is provided)\n",
    "        p2: Second dimension of template (required if template_2d is provided)\n",
    "        show_theory_bands: Whether to show colored bands between theory lines (default: True)\n",
    "        num_theory_lines: Number of theory lines to show (default: None = show all)\n",
    "        color_by_k: Whether to color lines by k value (default: True)\n",
    "        cmap: Colormap name for k-based coloring (default: 'viridis')\n",
    "    \"\"\"\n",
    "    if experiments is None:\n",
    "        experiments = get_sweep_experiments(sweep_dir)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Compute theory lines if template is provided\n",
    "    theory_levels = None\n",
    "    if template_2d is not None:\n",
    "        if p1 is None or p2 is None:\n",
    "            raise ValueError(\"p1 and p2 must be provided if template_2d is given\")\n",
    "\n",
    "        # Import the helper function (assuming it's in utils.py)\n",
    "        from gagf.rnns.utils import get_power_2d_adele\n",
    "\n",
    "        # Compute power spectrum of template\n",
    "        _, _, power = get_power_2d_adele(template_2d)\n",
    "        power_flat = np.sort(power.flatten()[power.flatten() > 1e-20])[::-1]\n",
    "\n",
    "        # Theory levels (cumulative tail sums)\n",
    "        alpha_values = np.array(\n",
    "            [np.sum(power_flat[k:]) for k in range(len(power_flat))]\n",
    "        )\n",
    "        coef = 1.0 / (p1 * p2)\n",
    "        theory_levels = coef * alpha_values  # strictly decreasing\n",
    "\n",
    "        # Limit number of lines if specified\n",
    "        if num_theory_lines is not None:\n",
    "            theory_levels = theory_levels[: num_theory_lines + 1]\n",
    "\n",
    "        # Generate colors for bands\n",
    "        n_bands = len(theory_levels) - 1\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, max(n_bands, 1)))\n",
    "\n",
    "        # Draw colored bands between theory lines\n",
    "        if show_theory_bands and n_bands > 0:\n",
    "            for i in range(n_bands):\n",
    "                y_top = theory_levels[i]\n",
    "                y_bot = theory_levels[i + 1]\n",
    "                ax.axhspan(\n",
    "                    y_bot,\n",
    "                    y_top,\n",
    "                    facecolor=colors[i % len(colors)],\n",
    "                    alpha=0.15,\n",
    "                    zorder=-3,\n",
    "                )\n",
    "\n",
    "        # Draw the black theory lines\n",
    "        for y in theory_levels:\n",
    "            ax.axhline(\n",
    "                y=y,\n",
    "                color=\"black\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1.5,\n",
    "                alpha=0.7,\n",
    "                zorder=-2,\n",
    "                label=\"_nolegend_\",\n",
    "            )\n",
    "\n",
    "    # Extract k values and set up colormap\n",
    "    k_values = {}\n",
    "    if color_by_k:\n",
    "        import re\n",
    "\n",
    "        for exp_name in experiments:\n",
    "            # Try to extract k value from experiment name (e.g., \"k_2_seqseq\" -> 2)\n",
    "            match = re.search(r\"k[_\\s]*(\\d+)\", exp_name, re.IGNORECASE)\n",
    "            if match:\n",
    "                k_values[exp_name] = int(match.group(1))\n",
    "\n",
    "        if k_values:\n",
    "            k_min = min(k_values.values())\n",
    "            k_max = max(k_values.values())\n",
    "            norm = plt.cm.colors.Normalize(vmin=k_min, vmax=k_max)\n",
    "            colormap = plt.cm.get_cmap(cmap)\n",
    "            scalar_map = plt.cm.ScalarMappable(norm=norm, cmap=colormap)\n",
    "\n",
    "    # Plot loss curves\n",
    "    for exp_name in experiments:\n",
    "        losses = load_experiment_losses(sweep_dir, exp_name, seed)\n",
    "        if loss_type in losses:\n",
    "            loss_history = losses[loss_type]\n",
    "\n",
    "            # Apply outlier removal if requested\n",
    "            if remove_outliers:\n",
    "                loss_history, outliers_found = remove_outliers_local(\n",
    "                    loss_history, window=outlier_window, threshold=outlier_threshold\n",
    "                )\n",
    "                if outliers_found:\n",
    "                    print(f\"Outliers from {exp_name} removed for plot\")\n",
    "\n",
    "            # Determine color\n",
    "            if color_by_k and exp_name in k_values:\n",
    "                color = scalar_map.to_rgba(k_values[exp_name])\n",
    "            else:\n",
    "                color = None  # Use default color cycle\n",
    "\n",
    "            ax.plot(loss_history, label=exp_name, alpha=0.8, linewidth=2, color=color)\n",
    "\n",
    "    ax.set_xlabel(\"Step\", fontsize=14)\n",
    "    ax.set_ylabel(f\"{loss_type.capitalize()} Loss\", fontsize=14)\n",
    "    title = f\"{loss_type.capitalize()} Loss Comparison - {Path(sweep_dir).name}\"\n",
    "    if remove_outliers:\n",
    "        title += \" (outliers removed)\"\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    if log_scale:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "    # Add colorbar if coloring by k\n",
    "    if color_by_k and k_values:\n",
    "        cbar = plt.colorbar(scalar_map, ax=ax, label=\"k (sequence length)\", pad=0.02)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax, theory_levels"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "fa6b246a"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "template_path = os.path.join(sweep_dir, \"k_2_seqseq\", \"seed_0\", \"template.npy\")\n",
    "template_2d = np.load(template_path)\n",
    "p1, p2 = template_2d.shape\n",
    "\n",
    "plt.imshow(template_2d)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "a8e3f5e3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# First, load the template from one of your experiments\n",
    "# (assuming they all use the same template)\n",
    "template_path = os.path.join(sweep_dir, \"k_2_seqseq\", \"seed_0\", \"template.npy\")\n",
    "template_2d = np.load(template_path)\n",
    "p1, p2 = template_2d.shape\n",
    "\n",
    "# Plot with theory lines\n",
    "fig, ax, theory_levels = plot_loss_comparison(\n",
    "    sweep_dir,\n",
    "    template_2d=template_2d,\n",
    "    p1=p1,\n",
    "    p2=p2,\n",
    "    remove_outliers=True,\n",
    "    num_theory_lines=10,  # Show first 10 theory lines\n",
    "    log_scale=True,\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "\n",
    "# Print the theory levels (plateau values)\n",
    "print(\"Theory plateau levels:\")\n",
    "for i, level in enumerate(theory_levels):\n",
    "    print(f\"  Plateau {i}: {level:.6e}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "dd4bf1a8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to reach plateau"
   ],
   "id": "ead6933c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def calculate_time_to_plateau(\n",
    "    sweep_dir: str,\n",
    "    template_2d: np.ndarray,\n",
    "    p1: int,\n",
    "    p2: int,\n",
    "    target_plateau_idx: int = 1,\n",
    "    loss_type: str = \"train\",\n",
    "    seed: int = 0,\n",
    "    tolerance: float = 1.1,\n",
    "    experiments: Optional[List[str]] = None,\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Calculate the step at which each experiment's loss reaches a target plateau.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        template_2d: 2D template array for computing theory lines\n",
    "        p1, p2: Dimensions of template\n",
    "        target_plateau_idx: Index of target plateau (1 = first drop, 2 = second drop, etc.)\n",
    "        loss_type: 'train' or 'val'\n",
    "        seed: Seed number\n",
    "        tolerance: Multiplier for plateau threshold (loss must be <= tolerance * plateau_level)\n",
    "        experiments: List of experiment names (None = all experiments)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping experiment names to step numbers\n",
    "    \"\"\"\n",
    "    from gagf.rnns.utils import get_power_2d_adele\n",
    "\n",
    "    # Compute theory levels\n",
    "    _, _, power = get_power_2d_adele(template_2d)\n",
    "    power_flat = np.sort(power.flatten()[power.flatten() > 1e-20])[::-1]\n",
    "    alpha_values = np.array([np.sum(power_flat[k:]) for k in range(len(power_flat))])\n",
    "    coef = 1.0 / (p1 * p2)\n",
    "    theory_levels = coef * alpha_values\n",
    "\n",
    "    if target_plateau_idx >= len(theory_levels):\n",
    "        raise ValueError(\n",
    "            f\"target_plateau_idx {target_plateau_idx} exceeds available plateaus ({len(theory_levels)})\"\n",
    "        )\n",
    "\n",
    "    target_level = theory_levels[target_plateau_idx]\n",
    "    threshold = tolerance * target_level\n",
    "\n",
    "    if experiments is None:\n",
    "        experiments = get_sweep_experiments(sweep_dir)\n",
    "\n",
    "    times_to_plateau = {}\n",
    "\n",
    "    for exp_name in experiments:\n",
    "        losses = load_experiment_losses(sweep_dir, exp_name, seed)\n",
    "        if loss_type in losses:\n",
    "            loss_history = losses[loss_type]\n",
    "\n",
    "            # Find first step where loss drops below threshold\n",
    "            crossing_indices = np.where(loss_history <= threshold)[0]\n",
    "\n",
    "            if len(crossing_indices) > 0:\n",
    "                times_to_plateau[exp_name] = crossing_indices[0]\n",
    "            else:\n",
    "                times_to_plateau[exp_name] = None  # Never reached\n",
    "\n",
    "    return times_to_plateau, theory_levels\n",
    "\n",
    "\n",
    "def plot_time_to_plateau(\n",
    "    sweep_dir: str,\n",
    "    template_2d: np.ndarray,\n",
    "    p1: int,\n",
    "    p2: int,\n",
    "    target_plateau_idx: int = 1,\n",
    "    loss_type: str = \"train\",\n",
    "    seed: int = 0,\n",
    "    tolerance: float = 1.1,\n",
    "    experiments: Optional[List[str]] = None,\n",
    "    figsize: tuple = (10, 6),\n",
    "    sort_by: str = \"time\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the time to reach a target plateau for different experiments.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        template_2d: 2D template array\n",
    "        p1, p2: Template dimensions\n",
    "        target_plateau_idx: Which plateau to measure (1 = first drop)\n",
    "        loss_type: 'train' or 'val'\n",
    "        seed: Seed number\n",
    "        tolerance: Multiplier for plateau threshold\n",
    "        experiments: List of experiment names (None = all)\n",
    "        figsize: Figure size\n",
    "        sort_by: 'time' (sort by time to plateau) or 'name' (alphabetical)\n",
    "    \"\"\"\n",
    "    times, theory_levels = calculate_time_to_plateau(\n",
    "        sweep_dir,\n",
    "        template_2d,\n",
    "        p1,\n",
    "        p2,\n",
    "        target_plateau_idx,\n",
    "        loss_type,\n",
    "        seed,\n",
    "        tolerance,\n",
    "        experiments,\n",
    "    )\n",
    "\n",
    "    # Filter out experiments that never reached the plateau\n",
    "    reached = {k: v for k, v in times.items() if v is not None}\n",
    "    not_reached = [k for k, v in times.items() if v is None]\n",
    "\n",
    "    if not reached:\n",
    "        print(\"No experiments reached the target plateau!\")\n",
    "        return\n",
    "\n",
    "    # Sort experiments\n",
    "    if sort_by == \"time\":\n",
    "        sorted_items = sorted(reached.items(), key=lambda x: x[1])\n",
    "    else:  # alphabetical\n",
    "        sorted_items = sorted(reached.items(), key=lambda x: x[0])\n",
    "\n",
    "    exp_names = [item[0] for item in sorted_items]\n",
    "    steps = [item[1] for item in sorted_items]\n",
    "\n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bars = ax.bar(range(len(exp_names)), steps, alpha=0.7, edgecolor=\"black\")\n",
    "\n",
    "    # Color bars by value (gradient)\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(steps)))\n",
    "    for bar, color in zip(bars, colors):\n",
    "        bar.set_color(color)\n",
    "\n",
    "    ax.set_xticks(range(len(exp_names)))\n",
    "    ax.set_xticklabels(exp_names, rotation=45, ha=\"right\")\n",
    "    ax.set_xlabel(\"Experiment\", fontsize=12)\n",
    "    ax.set_ylabel(\"Steps to Reach Plateau\", fontsize=12)\n",
    "    ax.set_title(\n",
    "        f\"Time to Reach Plateau {target_plateau_idx} (Level: {theory_levels[target_plateau_idx]:.2e})\",\n",
    "        fontsize=13,\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (bar, step) in enumerate(zip(bars, steps)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height,\n",
    "            f\"{int(step):,}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Print summary\n",
    "    print(\n",
    "        f\"\\nTime to reach plateau {target_plateau_idx} (threshold: {theory_levels[target_plateau_idx]:.2e}):\"\n",
    "    )\n",
    "    print(\"-\" * 60)\n",
    "    for name, step in sorted_items:\n",
    "        print(f\"  {name:30s}: {step:8,} steps\")\n",
    "\n",
    "    if not_reached:\n",
    "        print(f\"\\nExperiments that did not reach plateau {target_plateau_idx}:\")\n",
    "        for name in not_reached:\n",
    "            print(f\"  - {name}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax, times, theory_levels"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "4e1d02b4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_time_to_plateau(\n",
    "    sweep_dir: str,\n",
    "    template_2d: np.ndarray,\n",
    "    p1: int,\n",
    "    p2: int,\n",
    "    target_plateau_idx: int = 1,\n",
    "    loss_type: str = \"train\",\n",
    "    seed: int = 0,\n",
    "    tolerance: float = 1.1,\n",
    "    experiments: Optional[List[str]] = None,\n",
    "    figsize: tuple = (10, 6),\n",
    "    sort_by: str = \"time\",\n",
    "    color_by_k: bool = True,\n",
    "    cmap: str = \"viridis\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the time to reach a target plateau for different experiments.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        template_2d: 2D template array\n",
    "        p1, p2: Template dimensions\n",
    "        target_plateau_idx: Which plateau to measure (1 = first drop)\n",
    "        loss_type: 'train' or 'val'\n",
    "        seed: Seed number\n",
    "        tolerance: Multiplier for plateau threshold\n",
    "        experiments: List of experiment names (None = all)\n",
    "        figsize: Figure size\n",
    "        sort_by: 'time' (sort by time to plateau) or 'name' (alphabetical)\n",
    "        color_by_k: Whether to color bars by k value (default: True)\n",
    "        cmap: Colormap name for k-based coloring (default: 'viridis')\n",
    "    \"\"\"\n",
    "    times, theory_levels = calculate_time_to_plateau(\n",
    "        sweep_dir,\n",
    "        template_2d,\n",
    "        p1,\n",
    "        p2,\n",
    "        target_plateau_idx,\n",
    "        loss_type,\n",
    "        seed,\n",
    "        tolerance,\n",
    "        experiments,\n",
    "    )\n",
    "\n",
    "    # Filter out experiments that never reached the plateau\n",
    "    reached = {k: v for k, v in times.items() if v is not None}\n",
    "    not_reached = [k for k, v in times.items() if v is None]\n",
    "\n",
    "    if not reached:\n",
    "        print(\"No experiments reached the target plateau!\")\n",
    "        return\n",
    "\n",
    "    # Sort experiments\n",
    "    if sort_by == \"time\":\n",
    "        sorted_items = sorted(reached.items(), key=lambda x: x[1])\n",
    "    else:  # alphabetical\n",
    "        sorted_items = sorted(reached.items(), key=lambda x: x[0])\n",
    "\n",
    "    exp_names = [item[0] for item in sorted_items]\n",
    "    steps = [item[1] for item in sorted_items]\n",
    "\n",
    "    # Extract k values and set up colormap\n",
    "    k_values = []\n",
    "    if color_by_k:\n",
    "        import re\n",
    "\n",
    "        for exp_name in exp_names:\n",
    "            # Try to extract k value from experiment name (e.g., \"k_2_seqseq\" -> 2)\n",
    "            match = re.search(r\"k[_\\s]*(\\d+)\", exp_name, re.IGNORECASE)\n",
    "            if match:\n",
    "                k_values.append(int(match.group(1)))\n",
    "            else:\n",
    "                k_values.append(None)\n",
    "\n",
    "        # Check if we have valid k values\n",
    "        valid_k_values = [k for k in k_values if k is not None]\n",
    "        if valid_k_values:\n",
    "            k_min = min(valid_k_values)\n",
    "            k_max = max(valid_k_values)\n",
    "            norm = plt.cm.colors.Normalize(vmin=k_min, vmax=k_max)\n",
    "            colormap = plt.cm.get_cmap(cmap)\n",
    "            scalar_map = plt.cm.ScalarMappable(norm=norm, cmap=colormap)\n",
    "        else:\n",
    "            color_by_k = False  # Fall back if no k values found\n",
    "\n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bars = ax.bar(range(len(exp_names)), steps, alpha=0.7, edgecolor=\"black\")\n",
    "\n",
    "    # Color bars\n",
    "    if color_by_k and valid_k_values:\n",
    "        for bar, k_val in zip(bars, k_values):\n",
    "            if k_val is not None:\n",
    "                bar.set_color(scalar_map.to_rgba(k_val))\n",
    "            else:\n",
    "                bar.set_color(\"gray\")  # Fallback color\n",
    "    else:\n",
    "        # Color bars by position (gradient from blue to yellow)\n",
    "        colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(steps)))\n",
    "        for bar, color in zip(bars, colors):\n",
    "            bar.set_color(color)\n",
    "\n",
    "    ax.set_xticks(range(len(exp_names)))\n",
    "    ax.set_xticklabels(exp_names, rotation=45, ha=\"right\")\n",
    "    ax.set_xlabel(\"Experiment\", fontsize=12)\n",
    "    ax.set_ylabel(\"Steps to Reach Plateau\", fontsize=12)\n",
    "    ax.set_title(\n",
    "        f\"Time to Reach Plateau {target_plateau_idx} (Level: {theory_levels[target_plateau_idx]:.2e})\",\n",
    "        fontsize=13,\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (bar, step) in enumerate(zip(bars, steps)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height,\n",
    "            f\"{int(step):,}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    # Add colorbar if coloring by k\n",
    "    if color_by_k and valid_k_values:\n",
    "        cbar = plt.colorbar(scalar_map, ax=ax, label=\"k (sequence length)\", pad=0.02)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Print summary\n",
    "    print(\n",
    "        f\"\\nTime to reach plateau {target_plateau_idx} (threshold: {theory_levels[target_plateau_idx]:.2e}):\"\n",
    "    )\n",
    "    print(\"-\" * 60)\n",
    "    for name, step in sorted_items:\n",
    "        print(f\"  {name:30s}: {step:8,} steps\")\n",
    "\n",
    "    if not_reached:\n",
    "        print(f\"\\nExperiments that did not reach plateau {target_plateau_idx}:\")\n",
    "        for name in not_reached:\n",
    "            print(f\"  - {name}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax, times, theory_levels"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "b5b266d4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load template\n",
    "template_path = os.path.join(sweep_dir, \"k_2_seqseq\", \"seed_0\", \"template.npy\")\n",
    "template_2d = np.load(template_path)\n",
    "p1, p2 = template_2d.shape\n",
    "\n",
    "# get the times without plotting\n",
    "times_dict, theory_levels = calculate_time_to_plateau(\n",
    "    sweep_dir, template_2d, p1, p2, target_plateau_idx=1\n",
    ")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "b015323f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot time to first drop (plateau index 1)\n",
    "fig, ax, times, levels = plot_time_to_plateau(\n",
    "    sweep_dir,\n",
    "    template_2d,\n",
    "    p1,\n",
    "    p2,\n",
    "    target_plateau_idx=1,  # First drop\n",
    "    tolerance=1.1,  # Loss must be <= 1.1 * theory_level\n",
    "    sort_by=\"name\",\n",
    ")\n",
    "\n",
    "# Plot time to second drop (plateau index 2)\n",
    "plot_time_to_plateau(\n",
    "    sweep_dir,\n",
    "    template_2d,\n",
    "    p1,\n",
    "    p2,\n",
    "    target_plateau_idx=2,\n",
    "    tolerance=1.05,  # Second drop\n",
    "    cmap=\"viridis\",\n",
    "    sort_by=\"name\",\n",
    ")\n",
    "\n",
    "# Plot time to third drop (plateau index 3)\n",
    "plot_time_to_plateau(\n",
    "    sweep_dir,\n",
    "    template_2d,\n",
    "    p1,\n",
    "    p2,\n",
    "    target_plateau_idx=3,\n",
    "    tolerance=1.05,  # Second drop\n",
    "    cmap=\"viridis\",\n",
    "    sort_by=\"name\",\n",
    ")\n",
    "\n",
    "# Plot time to fourth drop (plateau index 4)\n",
    "plot_time_to_plateau(\n",
    "    sweep_dir,\n",
    "    template_2d,\n",
    "    p1,\n",
    "    p2,\n",
    "    target_plateau_idx=4,\n",
    "    tolerance=1.05,  # Second drop\n",
    "    cmap=\"viridis\",\n",
    "    sort_by=\"name\",\n",
    ");"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "eb63ea4a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-one sweep across different values of k (sequence length)"
   ],
   "id": "5536cdb2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1st sweep dir: \"/home/facosta/group-agf/sweeps/optim_sweep_20251113_001549\" (k=4, 5)\n",
    "- 2nd sweep dir: \"/home/facosta/group-agf/sweeps/optim_sweep_20251113_145528\" (k=2, 3)"
   ],
   "id": "063d9df4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_losses_from_multiple_sweeps(\n",
    "    sweep_experiments: Dict[str, List[str]], loss_type: str = \"train\", seed: int = 0\n",
    ") -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Load loss histories from experiments across multiple sweeps.\n",
    "\n",
    "    Args:\n",
    "        sweep_experiments: Dictionary mapping sweep_dir -> list of experiment names\n",
    "                          e.g., {sweep_dir_1: [\"exp1\", \"exp2\"], sweep_dir_2: [\"exp3\", \"exp4\"]}\n",
    "        loss_type: 'train' or 'val'\n",
    "        seed: Seed number\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping experiment names to their loss dictionaries\n",
    "        Note: Experiment names must be unique across sweeps\n",
    "    \"\"\"\n",
    "    all_losses = {}\n",
    "\n",
    "    for sweep_dir, exp_names in sweep_experiments.items():\n",
    "        for exp_name in exp_names:\n",
    "            losses = load_experiment_losses(sweep_dir, exp_name, seed)\n",
    "            if loss_type in losses:\n",
    "                # Store with experiment name as key\n",
    "                all_losses[exp_name] = losses\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: No {loss_type} loss found for {exp_name} in {sweep_dir}\"\n",
    "                )\n",
    "\n",
    "    return all_losses\n",
    "\n",
    "\n",
    "def create_color_mapping_from_multiple_sweeps(\n",
    "    sweep_experiments: Dict[str, List[str]],\n",
    "    parameter_path: str,\n",
    "    cmap: str = \"viridis\",\n",
    "    seed: int = 0,\n",
    "    log_scale: bool = False,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Create color mapping for experiments across multiple sweeps.\n",
    "\n",
    "    Args:\n",
    "        sweep_experiments: Dictionary mapping sweep_dir -> list of experiment names\n",
    "        parameter_path: Dot-separated path to parameter (e.g., 'data.batch_size')\n",
    "        cmap: Colormap name\n",
    "        seed: Seed number\n",
    "        log_scale: Whether to use logarithmic scale for color mapping\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (color_mapping dict, scalar_map, param_values dict)\n",
    "    \"\"\"\n",
    "    param_values = {}\n",
    "\n",
    "    # Extract parameters from all experiments across all sweeps\n",
    "    for sweep_dir, exp_names in sweep_experiments.items():\n",
    "        for exp_name in exp_names:\n",
    "            value = extract_config_parameter(sweep_dir, exp_name, parameter_path, seed)\n",
    "            if value is not None:\n",
    "                param_values[exp_name] = value\n",
    "\n",
    "    if not param_values:\n",
    "        print(f\"Warning: Could not extract '{parameter_path}' from any experiments\")\n",
    "        return {}, None, {}\n",
    "\n",
    "    # Create color mapping\n",
    "    values = list(param_values.values())\n",
    "    v_min = min(values)\n",
    "    v_max = max(values)\n",
    "\n",
    "    # Use log or linear normalization\n",
    "    if log_scale:\n",
    "        if v_min <= 0:\n",
    "            print(\n",
    "                f\"Warning: log_scale requested but found non-positive values (min={v_min}). Using linear scale.\"\n",
    "            )\n",
    "            norm = plt.cm.colors.Normalize(vmin=v_min, vmax=v_max)\n",
    "        else:\n",
    "            norm = plt.cm.colors.LogNorm(vmin=v_min, vmax=v_max)\n",
    "    else:\n",
    "        norm = plt.cm.colors.Normalize(vmin=v_min, vmax=v_max)\n",
    "\n",
    "    colormap = plt.cm.get_cmap(cmap)\n",
    "\n",
    "    color_mapping = {}\n",
    "    for exp_name, value in param_values.items():\n",
    "        color_mapping[exp_name] = colormap(norm(value))\n",
    "\n",
    "    scalar_map = plt.cm.ScalarMappable(norm=norm, cmap=colormap)\n",
    "\n",
    "    return color_mapping, scalar_map, param_values\n",
    "\n",
    "\n",
    "def plot_loss_comparison_multi_sweep(\n",
    "    sweep_experiments: Dict[str, List[str]],\n",
    "    loss_type: str = \"train\",\n",
    "    log_scale: bool = True,\n",
    "    figsize: tuple = (10, 6),\n",
    "    seed: int = 0,\n",
    "    remove_outliers: bool = False,\n",
    "    outlier_window: int = 10,\n",
    "    outlier_threshold: float = 3.0,\n",
    "    template_2d: Optional[np.ndarray] = None,\n",
    "    p1: Optional[int] = None,\n",
    "    p2: Optional[int] = None,\n",
    "    show_theory_bands: bool = True,\n",
    "    num_theory_lines: Optional[int] = None,\n",
    "    color_mapping: Optional[Dict[str, tuple]] = None,\n",
    "    colorbar_label: Optional[str] = None,\n",
    "    scalar_map: Optional[plt.cm.ScalarMappable] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot and compare loss curves from experiments across multiple sweeps.\n",
    "\n",
    "    Args:\n",
    "        sweep_experiments: Dictionary mapping sweep_dir -> list of experiment names\n",
    "                          e.g., {sweep_dir_1: [\"exp1\", \"exp2\"], sweep_dir_2: [\"exp3\"]}\n",
    "        loss_type: 'train' or 'val'\n",
    "        log_scale: Whether to use log scale for both axes\n",
    "        figsize: Figure size tuple\n",
    "        seed: Seed number\n",
    "        remove_outliers: Whether to remove outliers\n",
    "        outlier_window: Window size for outlier detection\n",
    "        outlier_threshold: Threshold for outlier detection\n",
    "        template_2d: Optional 2D template array for computing theory lines\n",
    "        p1, p2: Template dimensions\n",
    "        show_theory_bands: Whether to show colored bands between theory lines\n",
    "        num_theory_lines: Number of theory lines to show\n",
    "        color_mapping: Dictionary mapping experiment names to RGBA colors\n",
    "        colorbar_label: Label for colorbar\n",
    "        scalar_map: ScalarMappable for colorbar\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Compute theory lines if template is provided\n",
    "    theory_levels = None\n",
    "    if template_2d is not None:\n",
    "        if p1 is None or p2 is None:\n",
    "            raise ValueError(\"p1 and p2 must be provided if template_2d is given\")\n",
    "\n",
    "        from gagf.rnns.utils import get_power_2d_adele\n",
    "\n",
    "        _, _, power = get_power_2d_adele(template_2d)\n",
    "        power_flat = np.sort(power.flatten()[power.flatten() > 1e-20])[::-1]\n",
    "\n",
    "        alpha_values = np.array(\n",
    "            [np.sum(power_flat[k:]) for k in range(len(power_flat))]\n",
    "        )\n",
    "        coef = 1.0 / (p1 * p2)\n",
    "        theory_levels = coef * alpha_values\n",
    "\n",
    "        if num_theory_lines is not None:\n",
    "            theory_levels = theory_levels[: num_theory_lines + 1]\n",
    "\n",
    "        n_bands = len(theory_levels) - 1\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, max(n_bands, 1)))\n",
    "\n",
    "        if show_theory_bands and n_bands > 0:\n",
    "            for i in range(n_bands):\n",
    "                y_top = theory_levels[i]\n",
    "                y_bot = theory_levels[i + 1]\n",
    "                ax.axhspan(\n",
    "                    y_bot,\n",
    "                    y_top,\n",
    "                    facecolor=colors[i % len(colors)],\n",
    "                    alpha=0.15,\n",
    "                    zorder=-3,\n",
    "                )\n",
    "\n",
    "        for y in theory_levels:\n",
    "            ax.axhline(\n",
    "                y=y,\n",
    "                color=\"black\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1.5,\n",
    "                alpha=0.7,\n",
    "                zorder=-2,\n",
    "                label=\"_nolegend_\",\n",
    "            )\n",
    "\n",
    "    # Plot loss curves from all sweeps\n",
    "    for sweep_dir, exp_names in sweep_experiments.items():\n",
    "        for exp_name in exp_names:\n",
    "            losses = load_experiment_losses(sweep_dir, exp_name, seed)\n",
    "            if loss_type in losses:\n",
    "                loss_history = losses[loss_type]\n",
    "\n",
    "                if remove_outliers:\n",
    "                    loss_history, outliers_found = remove_outliers_local(\n",
    "                        loss_history, window=outlier_window, threshold=outlier_threshold\n",
    "                    )\n",
    "                    if outliers_found:\n",
    "                        print(f\"Outliers from {exp_name} removed for plot\")\n",
    "\n",
    "                # Determine color\n",
    "                if color_mapping and exp_name in color_mapping:\n",
    "                    color = color_mapping[exp_name]\n",
    "                else:\n",
    "                    color = None\n",
    "\n",
    "                ax.plot(\n",
    "                    loss_history, label=exp_name, alpha=0.8, linewidth=2, color=color\n",
    "                )\n",
    "\n",
    "    ax.set_xlabel(\"Step\", fontsize=14)\n",
    "    ax.set_ylabel(f\"{loss_type.capitalize()} Loss\", fontsize=14)\n",
    "    ax.set_title(\n",
    "        f\"{loss_type.capitalize()} Loss Comparison (Multiple Sweeps)\", fontsize=14\n",
    "    )\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    if log_scale:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "    if color_mapping and scalar_map is not None:\n",
    "        label = colorbar_label if colorbar_label else \"Parameter Value\"\n",
    "        cbar = plt.colorbar(scalar_map, ax=ax, label=label, pad=0.02)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax, theory_levels"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "d96f443e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define which experiments from which sweeps\n",
    "sweep_experiments = {\n",
    "    \"/home/facosta/group-agf/sweeps/optim_sweep_20251113_001549\": [\n",
    "        \"k_4_seqone\",\n",
    "        \"k_5_seqone\",\n",
    "    ],\n",
    "    \"/home/facosta/group-agf/sweeps/optim_sweep_20251113_145528\": [\n",
    "        \"k_2_seqone\",\n",
    "        \"k_3_seqone\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Load template (assuming same template across all)\n",
    "template_path = os.path.join(\n",
    "    list(sweep_experiments.keys())[0],  # First sweep\n",
    "    list(sweep_experiments.values())[0][0],  # First experiment\n",
    "    \"seed_0\",\n",
    "    \"template.npy\",\n",
    ")\n",
    "template_2d = np.load(template_path)\n",
    "p1, p2 = template_2d.shape\n",
    "\n",
    "# Create color mapping based on parameter across all sweeps\n",
    "color_map, scalar_map, k_values = create_color_mapping_from_multiple_sweeps(\n",
    "    sweep_experiments,\n",
    "    \"data.k\",  # or 'data.batch_size', 'training.learning_rate', etc.\n",
    "    cmap=\"viridis\",\n",
    "    log_scale=False,\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plot_loss_comparison_multi_sweep(\n",
    "    sweep_experiments,\n",
    "    template_2d=template_2d,\n",
    "    p1=p1,\n",
    "    p2=p2,\n",
    "    color_mapping=color_map,\n",
    "    colorbar_label=\"k (sequence length)\",\n",
    "    scalar_map=scalar_map,\n",
    "    num_theory_lines=10,\n",
    "    remove_outliers=False,\n",
    "    log_scale=True,\n",
    ")\n",
    "\n",
    "# Print extracted values to verify\n",
    "print(\"Extracted k values:\", k_values)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "9ac8e706"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def calculate_time_to_plateau_multi_sweep(\n",
    "    sweep_experiments: Dict[str, List[str]],\n",
    "    template_2d: np.ndarray,\n",
    "    p1: int,\n",
    "    p2: int,\n",
    "    target_plateau_idx: int = 1,\n",
    "    loss_type: str = \"train\",\n",
    "    seed: int = 0,\n",
    "    tolerance: float = 1.1,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate time to plateau for experiments across multiple sweeps.\n",
    "\n",
    "    Args:\n",
    "        sweep_experiments: Dictionary mapping sweep_dir -> list of experiment names\n",
    "        template_2d: 2D template array\n",
    "        p1, p2: Template dimensions\n",
    "        target_plateau_idx: Which plateau to measure (1 = first drop)\n",
    "        loss_type: 'train' or 'val'\n",
    "        seed: Seed number\n",
    "        tolerance: Multiplier for plateau threshold\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (times_to_plateau dict, theory_levels array)\n",
    "    \"\"\"\n",
    "    from gagf.rnns.utils import get_power_2d_adele\n",
    "\n",
    "    # Compute theory levels\n",
    "    _, _, power = get_power_2d_adele(template_2d)\n",
    "    power_flat = np.sort(power.flatten()[power.flatten() > 1e-20])[::-1]\n",
    "    alpha_values = np.array([np.sum(power_flat[k:]) for k in range(len(power_flat))])\n",
    "    coef = 1.0 / (p1 * p2)\n",
    "    theory_levels = coef * alpha_values\n",
    "\n",
    "    if target_plateau_idx >= len(theory_levels):\n",
    "        raise ValueError(\n",
    "            f\"target_plateau_idx {target_plateau_idx} exceeds available plateaus ({len(theory_levels)})\"\n",
    "        )\n",
    "\n",
    "    target_level = theory_levels[target_plateau_idx]\n",
    "    threshold = tolerance * target_level\n",
    "\n",
    "    times_to_plateau = {}\n",
    "\n",
    "    # Process all experiments across all sweeps\n",
    "    for sweep_dir, exp_names in sweep_experiments.items():\n",
    "        for exp_name in exp_names:\n",
    "            losses = load_experiment_losses(sweep_dir, exp_name, seed)\n",
    "            if loss_type in losses:\n",
    "                loss_history = losses[loss_type]\n",
    "\n",
    "                # Find first step where loss drops below threshold\n",
    "                crossing_indices = np.where(loss_history <= threshold)[0]\n",
    "\n",
    "                if len(crossing_indices) > 0:\n",
    "                    times_to_plateau[exp_name] = crossing_indices[0]\n",
    "                else:\n",
    "                    times_to_plateau[exp_name] = None  # Never reached\n",
    "\n",
    "    return times_to_plateau, theory_levels\n",
    "\n",
    "\n",
    "def plot_time_to_plateau_multi_sweep(\n",
    "    sweep_experiments: Dict[str, List[str]],\n",
    "    template_2d: np.ndarray,\n",
    "    p1: int,\n",
    "    p2: int,\n",
    "    target_plateau_idx: int = 1,\n",
    "    loss_type: str = \"train\",\n",
    "    seed: int = 0,\n",
    "    tolerance: float = 1.1,\n",
    "    figsize: tuple = (10, 6),\n",
    "    sort_by: str = \"time\",\n",
    "    color_mapping: Optional[Dict[str, tuple]] = None,\n",
    "    colorbar_label: Optional[str] = None,\n",
    "    scalar_map: Optional[plt.cm.ScalarMappable] = None,\n",
    "    show_not_reached: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot time to reach a target plateau for experiments across multiple sweeps.\n",
    "\n",
    "    Args:\n",
    "        sweep_experiments: Dictionary mapping sweep_dir -> list of experiment names\n",
    "        template_2d: 2D template array\n",
    "        p1, p2: Template dimensions\n",
    "        target_plateau_idx: Which plateau to measure (1 = first drop)\n",
    "        loss_type: 'train' or 'val'\n",
    "        seed: Seed number\n",
    "        tolerance: Multiplier for plateau threshold\n",
    "        figsize: Figure size\n",
    "        sort_by: 'time' (sort by time to plateau) or 'name' (alphabetical)\n",
    "        color_mapping: Dictionary mapping experiment names to RGBA colors\n",
    "        colorbar_label: Label for colorbar\n",
    "        scalar_map: ScalarMappable for colorbar\n",
    "        show_not_reached: Whether to show experiments that didn't reach plateau\n",
    "    \"\"\"\n",
    "    times, theory_levels = calculate_time_to_plateau_multi_sweep(\n",
    "        sweep_experiments,\n",
    "        template_2d,\n",
    "        p1,\n",
    "        p2,\n",
    "        target_plateau_idx,\n",
    "        loss_type,\n",
    "        seed,\n",
    "        tolerance,\n",
    "    )\n",
    "\n",
    "    # Separate reached vs not reached\n",
    "    reached = {k: v for k, v in times.items() if v is not None}\n",
    "    not_reached = {k: v for k, v in times.items() if v is None}\n",
    "\n",
    "    if not reached and not not_reached:\n",
    "        print(\"No experiments found!\")\n",
    "        return\n",
    "\n",
    "    # Sort experiments that reached the plateau\n",
    "    if reached:\n",
    "        if sort_by == \"time\":\n",
    "            sorted_reached = sorted(reached.items(), key=lambda x: x[1])\n",
    "        else:  # alphabetical\n",
    "            sorted_reached = sorted(reached.items(), key=lambda x: x[0])\n",
    "    else:\n",
    "        sorted_reached = []\n",
    "\n",
    "    # Add not-reached experiments at the end if requested\n",
    "    if show_not_reached and not_reached:\n",
    "        not_reached_sorted = sorted(not_reached.keys())\n",
    "        exp_names = [item[0] for item in sorted_reached] + not_reached_sorted\n",
    "        # Use a very large value for visualization (e.g., max reached time * 1.5)\n",
    "        max_reached_time = max([v for v in reached.values()]) if reached else 10000\n",
    "        placeholder_time = max_reached_time * 1.3\n",
    "        steps = [item[1] for item in sorted_reached] + [placeholder_time] * len(\n",
    "            not_reached_sorted\n",
    "        )\n",
    "        reached_mask = [True] * len(sorted_reached) + [False] * len(not_reached_sorted)\n",
    "    else:\n",
    "        exp_names = [item[0] for item in sorted_reached]\n",
    "        steps = [item[1] for item in sorted_reached]\n",
    "        reached_mask = [True] * len(sorted_reached)\n",
    "\n",
    "    if not exp_names:\n",
    "        print(\"No experiments to plot!\")\n",
    "        return\n",
    "\n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bars = ax.bar(range(len(exp_names)), steps, alpha=0.7, edgecolor=\"black\")\n",
    "\n",
    "    # Color bars\n",
    "    for i, (bar, exp_name, did_reach) in enumerate(zip(bars, exp_names, reached_mask)):\n",
    "        if not did_reach:\n",
    "            # Gray out experiments that didn't reach plateau\n",
    "            bar.set_color(\"lightgray\")\n",
    "            bar.set_alpha(0.4)\n",
    "            bar.set_hatch(\"///\")\n",
    "        elif color_mapping and exp_name in color_mapping:\n",
    "            bar.set_color(color_mapping[exp_name])\n",
    "        else:\n",
    "            # Default gradient coloring\n",
    "            colors = plt.cm.viridis(\n",
    "                np.linspace(0.2, 0.9, len([m for m in reached_mask if m]))\n",
    "            )\n",
    "            bar.set_color(colors[i] if did_reach else \"lightgray\")\n",
    "\n",
    "    ax.set_xticks(range(len(exp_names)))\n",
    "    ax.set_xticklabels(exp_names, rotation=45, ha=\"right\")\n",
    "    ax.set_xlabel(\"Experiment\", fontsize=12)\n",
    "    ax.set_ylabel(\"Steps to Reach Plateau\", fontsize=12)\n",
    "    ax.set_title(\n",
    "        f\"Time to Reach Plateau {target_plateau_idx} (Level: {theory_levels[target_plateau_idx]:.2e})\",\n",
    "        fontsize=13,\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, (bar, step, did_reach, exp_name) in enumerate(\n",
    "        zip(bars, steps, reached_mask, exp_names)\n",
    "    ):\n",
    "        height = bar.get_height()\n",
    "        if did_reach:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height,\n",
    "                f\"{int(step):,}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=9,\n",
    "            )\n",
    "        else:\n",
    "            # Add \"Did not reach\" annotation\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height / 2,\n",
    "                \"Did not\\nreach\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=8,\n",
    "                style=\"italic\",\n",
    "                color=\"darkgray\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "\n",
    "    # Add colorbar if color mapping provided (only for experiments that reached)\n",
    "    if color_mapping and scalar_map is not None and reached:\n",
    "        label = colorbar_label if colorbar_label else \"Parameter Value\"\n",
    "        cbar = plt.colorbar(scalar_map, ax=ax, label=label, pad=0.02)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Print summary\n",
    "    print(\n",
    "        f\"\\nTime to reach plateau {target_plateau_idx} (threshold: {theory_levels[target_plateau_idx]:.2e}):\"\n",
    "    )\n",
    "    print(\"-\" * 60)\n",
    "    if reached:\n",
    "        for name, step in sorted_reached:\n",
    "            print(f\"  {name:30s}: {step:8,} steps\")\n",
    "\n",
    "    if not_reached:\n",
    "        print(f\"\\nExperiments that did not reach plateau {target_plateau_idx}:\")\n",
    "        for name in not_reached_sorted:\n",
    "            print(f\"  - {name}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax, times, theory_levels"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "1019938c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define your experiments across multiple sweeps\n",
    "sweep_experiments = {\n",
    "    \"/home/facosta/group-agf/sweeps/optim_sweep_20251113_001549\": [\n",
    "        \"k_4_seqone\",\n",
    "        \"k_5_seqone\",\n",
    "    ],\n",
    "    \"/home/facosta/group-agf/sweeps/optim_sweep_20251113_145528\": [\n",
    "        \"k_2_seqone\",\n",
    "        \"k_3_seqone\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Load template\n",
    "template_path = os.path.join(\n",
    "    \"/home/facosta/group-agf/sweeps/optim_sweep_20251113_001549\",\n",
    "    \"k_4_seqone\",\n",
    "    \"seed_0\",\n",
    "    \"template.npy\",\n",
    ")\n",
    "template_2d = np.load(template_path)\n",
    "p1, p2 = template_2d.shape\n",
    "\n",
    "# Create color mapping by k value\n",
    "color_map, scalar_map, k_values = create_color_mapping_from_multiple_sweeps(\n",
    "    sweep_experiments, \"data.k\", cmap=\"viridis\", log_scale=False\n",
    ")\n",
    "\n",
    "# Plot time to first plateau\n",
    "fig, ax, times, levels = plot_time_to_plateau_multi_sweep(\n",
    "    sweep_experiments,\n",
    "    template_2d,\n",
    "    p1,\n",
    "    p2,\n",
    "    target_plateau_idx=1,  # First drop\n",
    "    tolerance=1.1,\n",
    "    color_mapping=color_map,\n",
    "    colorbar_label=\"k (sequence length)\",\n",
    "    scalar_map=scalar_map,\n",
    "    sort_by=\"name\",  # or 'time'\n",
    "    show_not_reached=True,  # Show experiments that didn't reach plateau\n",
    ")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "84c284b1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size sweep (seq-to-one, k=3)"
   ],
   "id": "78bfc515"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def extract_config_parameter(\n",
    "    sweep_dir: str, experiment_name: str, parameter_path: str, seed: int = 0\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    Extract a parameter value from an experiment's config file.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        experiment_name: Name of experiment\n",
    "        parameter_path: Dot-separated path to parameter (e.g., 'data.batch_size', 'training.learning_rate')\n",
    "        seed: Seed number (for getting from seed_X/config.yaml)\n",
    "\n",
    "    Returns:\n",
    "        Parameter value or None if not found\n",
    "    \"\"\"\n",
    "    # Try configs directory first\n",
    "    config_path = Path(sweep_dir) / \"configs\" / f\"{experiment_name}_config.yaml\"\n",
    "\n",
    "    # If not there, try seed_X directory\n",
    "    if not config_path.exists():\n",
    "        config_path = Path(sweep_dir) / experiment_name / f\"seed_{seed}\" / \"config.yaml\"\n",
    "\n",
    "    if not config_path.exists():\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "\n",
    "        # Navigate through nested structure using dot notation\n",
    "        value = config\n",
    "        for key in parameter_path.split(\".\"):\n",
    "            value = value[key]\n",
    "\n",
    "        return value\n",
    "    except (KeyError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_color_mapping(\n",
    "    sweep_dir: str,\n",
    "    parameter_path: str,\n",
    "    experiments: Optional[List[str]] = None,\n",
    "    cmap: str = \"viridis\",\n",
    "    seed: int = 0,\n",
    "    log_scale: bool = False,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Create a color mapping for experiments based on a config parameter.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        parameter_path: Dot-separated path to parameter (e.g., 'data.batch_size')\n",
    "        experiments: List of experiment names (None = all)\n",
    "        cmap: Colormap name\n",
    "        seed: Seed number\n",
    "        log_scale: Whether to use logarithmic scale for color mapping\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (color_mapping dict, scalar_map, param_values dict)\n",
    "    \"\"\"\n",
    "    if experiments is None:\n",
    "        experiments = get_sweep_experiments(sweep_dir)\n",
    "\n",
    "    # Extract parameter values for all experiments\n",
    "    param_values = {}\n",
    "    for exp_name in experiments:\n",
    "        value = extract_config_parameter(sweep_dir, exp_name, parameter_path, seed)\n",
    "        if value is not None:\n",
    "            param_values[exp_name] = value\n",
    "\n",
    "    if not param_values:\n",
    "        print(f\"Warning: Could not extract '{parameter_path}' from any experiments\")\n",
    "        return {}, None, {}\n",
    "\n",
    "    # Create color mapping\n",
    "    values = list(param_values.values())\n",
    "    v_min = min(values)\n",
    "    v_max = max(values)\n",
    "\n",
    "    # Use log or linear normalization\n",
    "    if log_scale:\n",
    "        if v_min <= 0:\n",
    "            print(\n",
    "                f\"Warning: log_scale requested but found non-positive values (min={v_min}). Using linear scale.\"\n",
    "            )\n",
    "            norm = plt.cm.colors.Normalize(vmin=v_min, vmax=v_max)\n",
    "        else:\n",
    "            norm = plt.cm.colors.LogNorm(vmin=v_min, vmax=v_max)\n",
    "    else:\n",
    "        norm = plt.cm.colors.Normalize(vmin=v_min, vmax=v_max)\n",
    "\n",
    "    colormap = plt.cm.get_cmap(cmap)\n",
    "\n",
    "    color_mapping = {}\n",
    "    for exp_name, value in param_values.items():\n",
    "        color_mapping[exp_name] = colormap(norm(value))\n",
    "\n",
    "    # Also return the scalar mappable for colorbar\n",
    "    scalar_map = plt.cm.ScalarMappable(norm=norm, cmap=colormap)\n",
    "\n",
    "    return color_mapping, scalar_map, param_values"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "ac01c062"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_loss_comparison(\n",
    "    sweep_dir: str,\n",
    "    experiments: Optional[List[str]] = None,\n",
    "    loss_type: str = \"train\",\n",
    "    log_scale: bool = True,\n",
    "    figsize: tuple = (10, 6),\n",
    "    seed: int = 0,\n",
    "    remove_outliers: bool = False,\n",
    "    outlier_window: int = 10,\n",
    "    outlier_threshold: float = 3.0,\n",
    "    template_2d: Optional[np.ndarray] = None,\n",
    "    p1: Optional[int] = None,\n",
    "    p2: Optional[int] = None,\n",
    "    show_theory_bands: bool = True,\n",
    "    num_theory_lines: Optional[int] = None,\n",
    "    color_mapping: Optional[Dict[str, tuple]] = None,\n",
    "    colorbar_label: Optional[str] = None,\n",
    "    scalar_map: Optional[plt.cm.ScalarMappable] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot and compare loss curves from multiple experiments.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to sweep directory\n",
    "        experiments: List of experiment names to plot (None = all experiments)\n",
    "        loss_type: 'train' or 'val'\n",
    "        log_scale: Whether to use log scale for both axes\n",
    "        figsize: Figure size tuple\n",
    "        seed: Seed number (default: 0)\n",
    "        remove_outliers: Whether to remove outliers using local outlier replacement\n",
    "        outlier_window: Window size for outlier detection (default: 10)\n",
    "        outlier_threshold: Threshold in standard deviations for outlier detection (default: 3.0)\n",
    "        template_2d: Optional 2D template array for computing theory lines\n",
    "        p1: First dimension of template (required if template_2d is provided)\n",
    "        p2: Second dimension of template (required if template_2d is provided)\n",
    "        show_theory_bands: Whether to show colored bands between theory lines (default: True)\n",
    "        num_theory_lines: Number of theory lines to show (default: None = show all)\n",
    "        color_mapping: Dictionary mapping experiment names to RGBA colors\n",
    "        colorbar_label: Label for colorbar (if color_mapping provided)\n",
    "        scalar_map: ScalarMappable for colorbar (if color_mapping provided)\n",
    "    \"\"\"\n",
    "    if experiments is None:\n",
    "        experiments = get_sweep_experiments(sweep_dir)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Compute theory lines if template is provided\n",
    "    theory_levels = None\n",
    "    if template_2d is not None:\n",
    "        if p1 is None or p2 is None:\n",
    "            raise ValueError(\"p1 and p2 must be provided if template_2d is given\")\n",
    "\n",
    "        # Import the helper function (assuming it's in utils.py)\n",
    "        from gagf.rnns.utils import get_power_2d_adele\n",
    "\n",
    "        # Compute power spectrum of template\n",
    "        _, _, power = get_power_2d_adele(template_2d)\n",
    "        power_flat = np.sort(power.flatten()[power.flatten() > 1e-20])[::-1]\n",
    "\n",
    "        # Theory levels (cumulative tail sums)\n",
    "        alpha_values = np.array(\n",
    "            [np.sum(power_flat[k:]) for k in range(len(power_flat))]\n",
    "        )\n",
    "        coef = 1.0 / (p1 * p2)\n",
    "        theory_levels = coef * alpha_values  # strictly decreasing\n",
    "\n",
    "        # Limit number of lines if specified\n",
    "        if num_theory_lines is not None:\n",
    "            theory_levels = theory_levels[: num_theory_lines + 1]\n",
    "\n",
    "        # Generate colors for bands\n",
    "        n_bands = len(theory_levels) - 1\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, max(n_bands, 1)))\n",
    "\n",
    "        # Draw colored bands between theory lines\n",
    "        if show_theory_bands and n_bands > 0:\n",
    "            for i in range(n_bands):\n",
    "                y_top = theory_levels[i]\n",
    "                y_bot = theory_levels[i + 1]\n",
    "                ax.axhspan(\n",
    "                    y_bot,\n",
    "                    y_top,\n",
    "                    facecolor=colors[i % len(colors)],\n",
    "                    alpha=0.15,\n",
    "                    zorder=-3,\n",
    "                )\n",
    "\n",
    "        # Draw the black theory lines\n",
    "        for y in theory_levels:\n",
    "            ax.axhline(\n",
    "                y=y,\n",
    "                color=\"black\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1.5,\n",
    "                alpha=0.7,\n",
    "                zorder=-2,\n",
    "                label=\"_nolegend_\",\n",
    "            )\n",
    "\n",
    "    # Plot loss curves\n",
    "    for exp_name in experiments:\n",
    "        losses = load_experiment_losses(sweep_dir, exp_name, seed)\n",
    "        if loss_type in losses:\n",
    "            loss_history = losses[loss_type]\n",
    "\n",
    "            # Apply outlier removal if requested\n",
    "            if remove_outliers:\n",
    "                loss_history, outliers_found = remove_outliers_local(\n",
    "                    loss_history, window=outlier_window, threshold=outlier_threshold\n",
    "                )\n",
    "                if outliers_found:\n",
    "                    print(f\"Outliers from {exp_name} removed for plot\")\n",
    "\n",
    "            # Determine color\n",
    "            if color_mapping and exp_name in color_mapping:\n",
    "                color = color_mapping[exp_name]\n",
    "            else:\n",
    "                color = None  # Use default color cycle\n",
    "\n",
    "            ax.plot(loss_history, label=exp_name, alpha=0.8, linewidth=2, color=color)\n",
    "\n",
    "    ax.set_xlabel(\"Step\", fontsize=14)\n",
    "    ax.set_ylabel(f\"{loss_type.capitalize()} Loss\", fontsize=14)\n",
    "    title = f\"{loss_type.capitalize()} Loss Comparison - {Path(sweep_dir).name}\"\n",
    "    if remove_outliers:\n",
    "        title += \" (outliers removed)\"\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    if log_scale:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "    # Add colorbar if color mapping provided\n",
    "    if color_mapping and scalar_map is not None:\n",
    "        label = colorbar_label if colorbar_label else \"Parameter Value\"\n",
    "        cbar = plt.colorbar(scalar_map, ax=ax, label=label, pad=0.02)\n",
    "        cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax, theory_levels"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "b2da02fb"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set up your sweep directory\n",
    "batch_sweep_dir = \"/home/facosta/group-agf/sweeps/batch_sweep_20251113_171834\"\n",
    "\n",
    "# Get all experiments in the sweep\n",
    "batch_experiments = get_sweep_experiments(batch_sweep_dir)\n",
    "print(f\"Found experiments: {batch_experiments}\")\n",
    "\n",
    "# Load losses for all experiments\n",
    "batch_all_losses = load_all_sweep_losses(batch_sweep_dir)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "8b2ce522"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# First, load the template from one of your experiments\n",
    "# (assuming they all use the same template)\n",
    "template_path = os.path.join(batch_sweep_dir, \"batch_1000\", \"seed_0\", \"template.npy\")\n",
    "template_2d = np.load(template_path)\n",
    "p1, p2 = template_2d.shape\n",
    "\n",
    "plt.imshow(template_2d)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "520500f3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example 1: Color by batch_size\n",
    "color_map, scalar_map, batch_values = create_color_mapping(\n",
    "    batch_sweep_dir,\n",
    "    \"data.batch_size\",\n",
    "    cmap=\"viridis\",\n",
    "    log_scale=True,\n",
    ")\n",
    "\n",
    "plot_loss_comparison(\n",
    "    batch_sweep_dir,\n",
    "    template_2d=template_2d,\n",
    "    p1=p1,\n",
    "    p2=p2,\n",
    "    color_mapping=color_map,\n",
    "    colorbar_label=\"Batch Size\",\n",
    "    scalar_map=scalar_map,\n",
    "    num_theory_lines=10,\n",
    "    remove_outliers=True,\n",
    "    log_scale=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Print the extracted values to verify\n",
    "print(\"Batch sizes:\", batch_values)\n",
    "\n",
    "# Print the theory levels (plateau values)\n",
    "print(\"Theory plateau levels:\")\n",
    "for i, level in enumerate(theory_levels):\n",
    "    print(f\"  Plateau {i}: {level:.6e}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "b9761849"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Scaling Sweep Heatmap\n",
    "\n",
    "Visualize the relationship between sequence length (k) and hidden dimension (width) for SequentialMLP.\n",
    "\n",
    "**Sweep parameters:**\n",
    "- Model: SequentialMLP\n",
    "- Dimension: 1, p = 10\n",
    "- k values: 2, 3, 4, 5, 6 (5 values)\n",
    "- hidden_dim values: 60, 360, 2160, 12960, 77760 (5 values = 10\u00d76\u00b9 through 10\u00d76\u2075)\n",
    "- num_steps varies with k: k=2\u219250k, k=3\u2192100k, k=4\u2192150k, k=5\u2192200k, k=6\u2192250k\n",
    "- Total: 25 experiments \u00d7 3 seeds = 75 runs"
   ],
   "id": "7acdd373"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_scaling_heatmap(\n",
    "    sweep_dir: str,\n",
    "    k_values: list = [2, 3, 4, 5, 6, 7, 8],\n",
    "    hidden_dims: list = [60, 360, 2160, 12960, 77760, 466560, 2799360],\n",
    "    use_log_scale: bool = True,\n",
    "    save_path: str = None\n",
    "):    \n",
    "    \"\"\"\n",
    "    Create a heatmap of final train loss vs k and hidden_dim.\n",
    "    \n",
    "    Args:\n",
    "        sweep_dir: Path to the sweep directory\n",
    "        k_values: List of k values (x-axis)\n",
    "        hidden_dims: List of hidden dimension values (y-axis)\n",
    "        use_log_scale: Whether to use log scale for the loss values\n",
    "        save_path: Optional path to save the figure\n",
    "    \"\"\"\n",
    "    # Load results\n",
    "    grid, std_grid = load_sweep_results_grid(sweep_dir, k_values, hidden_dims)\n",
    "    \n",
    "    # Apply log scale if requested\n",
    "    plot_grid = np.log10(grid) if use_log_scale else grid\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))    \n",
    "    \n",
    "    \n",
    "    # Create heatmap\n",
    "    im = ax.imshow(plot_grid, aspect='auto', cmap='viridis', origin='lower')\n",
    "    \n",
    "    # Set ticks and labels\n",
    "    ax.set_xticks(range(len(k_values)))\n",
    "    ax.set_yticks(range(len(hidden_dims)))\n",
    "    ax.set_xticklabels(k_values)\n",
    "    ax.set_yticklabels([f\"{h:,}\" for h in hidden_dims])\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel('Sequence Length (k)', fontsize=14)\n",
    "    ax.set_ylabel('Hidden Dimension (width)', fontsize=14)\n",
    "    title = 'Final Train Loss: SequentialMLP Scaling'\n",
    "    if use_log_scale:\n",
    "        title += ' (log\u2081\u2080)'\n",
    "    ax.set_title(title, fontsize=16, pad=20)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar_label = 'log\u2081\u2080(Train Loss)' if use_log_scale else 'Train Loss'\n",
    "    cbar.set_label(cbar_label, fontsize=12)\n",
    "    \n",
    "    # Add text annotations\n",
    "\n",
    "    # Add text annotations\n",
    "    for i in range(len(hidden_dims)):\n",
    "        for j in range(len(k_values)):\n",
    "            if not np.isnan(grid[i, j]):\n",
    "                text_val = f\"{grid[i, j]:.2e}\"\n",
    "                text_color = 'white' if plot_grid[i, j] < plot_grid[~np.isnan(plot_grid)].mean() else 'black'\n",
    "                ax.text(j, i, text_val, ha='center', va='center', \n",
    "                       color=text_color, fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return grid"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "92d3289e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": [],
   "id": "2e5c22df"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": [],
   "id": "b10c9d83"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gagf-PDhBFja6-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}