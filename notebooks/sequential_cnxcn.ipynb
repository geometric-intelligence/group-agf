{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Group Composition on $C_n \\times C_n$\n",
    "\n",
    "**Group:** Product of cyclic groups $C_n \\times C_n$ of order $n^2$.  \n",
    "**Task:** Given a sequence of $k$ group elements $g_1, \\ldots, g_k \\in C_n \\times C_n$, predict their cumulative product.  \n",
    "**Sequence length:** $k = 3$ (sequential composition).  \n",
    "**Architecture:** `QuadraticRNN` with quadratic recurrence.  \n",
    "**Key result:** The RNN composes elements sequentially in $k$ steps, exploiting associativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import src.dataset as dataset\n",
    "import src.model as model\n",
    "import src.optimizer as optimizer\n",
    "import src.power as power\n",
    "import src.template as template\n",
    "import src.train as train_mod\n",
    "import src.viz as viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODE = os.environ.get(\"NOTEBOOK_TEST_MODE\", \"0\") == \"1\"\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "p1, p2 = 7, 7  # Cn x Cn dimensions\n",
    "p_flat = p1 * p2\n",
    "k = 3  # Sequence length\n",
    "hidden_dim = 50 if TEST_MODE else 200\n",
    "epochs = 2 if TEST_MODE else 5\n",
    "num_samples = 100 if TEST_MODE else 10000\n",
    "batch_size = 64 if TEST_MODE else 1000\n",
    "lr = 1e-3\n",
    "init_scale = 1e-2\n",
    "mode = \"sampled\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "FIGURES_DIR = \"figures\"\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Group: C_{p1} x C_{p2}, order {p_flat}\")\n",
    "print(f\"Sequence length: k={k}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 2D template with known Fourier structure\n",
    "tpl_2d = template.unique_freqs_2d(p1, p2, n_freqs=5, seed=seed)\n",
    "\n",
    "# Build sequential dataset\n",
    "X, Y, sequence_xy = dataset.build_modular_addition_sequence_dataset_2d(\n",
    "    p1, p2, tpl_2d, k, mode=mode, num_samples=num_samples,\n",
    ")\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "\n",
    "ds = TensorDataset(X_tensor, Y_tensor)\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Dataset: {len(ds)} samples\")\n",
    "print(f\"X shape: {X_tensor.shape} (N, k, p1*p2)\")\n",
    "print(f\"Y shape: {Y_tensor.shape} (N, p1*p2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize template\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "im = ax1.imshow(tpl_2d, cmap=\"RdBu_r\")\n",
    "ax1.set_title(f\"Template on $C_{{{p1}}} \\\\times C_{{{p2}}}$\")\n",
    "ax1.set_xlabel(\"$C_{\" + str(p2) + \"}$ index\")\n",
    "ax1.set_ylabel(\"$C_{\" + str(p1) + \"}$ index\")\n",
    "plt.colorbar(im, ax=ax1)\n",
    "\n",
    "# Show 2D power spectrum\n",
    "pwr_2d = power.get_power_2d(tpl_2d, no_freq=True)\n",
    "im2 = ax2.imshow(np.log10(pwr_2d + 1e-12), cmap=\"hot\")\n",
    "ax2.set_title(\"Log power spectrum\")\n",
    "ax2.set_xlabel(\"Freq $k_2$\")\n",
    "ax2.set_ylabel(\"Freq $k_1$\")\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIGURES_DIR}/sequential_cnxcn_template.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.QuadraticRNN(\n",
    "    p=p_flat,\n",
    "    d=hidden_dim,\n",
    "    template=tpl_2d.flatten(),\n",
    "    init_scale=init_scale,\n",
    ")\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "opt = optimizer.HybridRNNOptimizer(net, lr=lr)\n",
    "\n",
    "print(f\"Model: QuadraticRNN(p={p_flat}, d={hidden_dim}, k={k})\")\n",
    "print(f\"Optimizer: HybridRNNOptimizer(lr={lr})\")\n",
    "print(f\"Training for {epochs} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, val_loss_history, param_history, param_save_epochs, final_epoch = train_mod.train(\n",
    "    net,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    opt,\n",
    "    epochs=epochs,\n",
    "    verbose_interval=1,\n",
    "    save_param_interval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot training loss with theoretical levels\n",
    "ax.plot(loss_history, lw=4, label=\"Train loss\")\n",
    "\n",
    "theory = power.theoretical_loss_levels_2d(tpl_2d)\n",
    "for level in theory[\"levels\"]:\n",
    "    ax.axhline(y=level, color=\"black\", linestyle=\"--\", linewidth=1.5, zorder=-2)\n",
    "\n",
    "ax.set_xlabel(\"Epochs\", fontsize=18)\n",
    "ax.set_ylabel(\"Train Loss\", fontsize=18)\n",
    "ax.set_title(f\"Training loss (sequential $k={k}$ on $C_{{{p1}}} \\\\times C_{{{p2}}}$)\", fontsize=18)\n",
    "viz.style_axes(ax)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIGURES_DIR}/sequential_cnxcn_loss.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions vs ground truth\n",
    "net.load_state_dict(param_history[-1])\n",
    "net.eval()\n",
    "\n",
    "n_examples = 3\n",
    "indices = np.random.choice(len(Y_tensor), size=n_examples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_examples, 2, figsize=(8, 3 * n_examples))\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_batch = X_tensor[indices]\n",
    "    preds = net(x_batch).detach().cpu().numpy()\n",
    "    truths = Y_tensor[indices].detach().cpu().numpy()\n",
    "\n",
    "for i in range(n_examples):\n",
    "    axes[i, 0].imshow(truths[i].reshape(p1, p2), cmap=\"RdBu_r\")\n",
    "    axes[i, 0].set_title(\"Ground truth\")\n",
    "    axes[i, 1].imshow(preds[i].reshape(p1, p2), cmap=\"RdBu_r\")\n",
    "    axes[i, 1].set_title(\"Prediction\")\n",
    "\n",
    "plt.suptitle(f\"Predictions (sequential $k={k}$ on $C_{{{p1}}} \\\\times C_{{{p2}}}$, epoch {final_epoch})\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIGURES_DIR}/sequential_cnxcn_predictions.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group-agf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
