{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Scaling: $H$ vs $|G|$ \n",
    "\n",
    "Hidden neurons vs group size scaling experiments."
   ],
   "id": "c8c5c4b6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ],
   "id": "155908c2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# jupyter black formatter\n",
    "%load_ext jupyter_black\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "gitroot_path = subprocess.check_output(\n",
    "    [\"git\", \"rev-parse\", \"--show-toplevel\"], universal_newlines=True\n",
    ").strip()\n",
    "\n",
    "os.chdir(gitroot_path)\n",
    "print(\"Working directory: \", os.getcwd())\n",
    "\n",
    "if gitroot_path not in sys.path:\n",
    "    sys.path.insert(0, gitroot_path)\n",
    "print(\"Directory added to path: \", gitroot_path)\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "7fc4c5b6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify experiment directory"
   ],
   "id": "9831010d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# sweep_dir = \"/home/facosta/group-agf/sweeps/onehot_scaling_sweep_20251215_175955\"\n",
    "sweep_dir = \"/home/facosta/group-agf/sweep_results/onehot_scaling_sweep_20260112_022012\"\n",
    "print(os.path.exists(sweep_dir))"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "b9f8fc25"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to Convergence"
   ],
   "id": "d8342c22"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_sweep_results_grid_convergence_p_h(\n",
    "    sweep_dir: str,\n",
    "    k: int,\n",
    "    p_values: list,\n",
    "    hidden_dims: list,\n",
    "    reduction_threshold: float = 0.99,\n",
    "    max_p: int = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load sweep results and compute steps to convergence for p vs hidden_dim sweep.\n",
    "\n",
    "    Updated for experiment naming: k{k}_p{p}_h{h}\n",
    "    Only loads completed experiments (checks for run_summary.yaml).\n",
    "\n",
    "    Convergence is defined as reaching `reduction_threshold` loss reduction\n",
    "    (e.g., 0.99 = 99% reduction from initial loss).\n",
    "\n",
    "    If convergence is not reached, the grid point is set to NaN (blacked out).\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to the sweep directory\n",
    "        k: Sequence length parameter (2, 3, or 4)\n",
    "        p_values: List of p (group size) values\n",
    "        hidden_dims: List of hidden dimension values\n",
    "        reduction_threshold: Fraction of loss reduction to consider converged\n",
    "        max_p: Maximum p value to include (filters incomplete experiments)\n",
    "\n",
    "    Returns:\n",
    "        grid: 2D array with mean steps to convergence (NaN if didn't converge)\n",
    "              Shape: (len(hidden_dims), len(p_values))\n",
    "        std_grid: 2D array with standard deviations across seeds\n",
    "    \"\"\"\n",
    "    sweep_path = Path(sweep_dir)\n",
    "\n",
    "    grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "    std_grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "\n",
    "    for i, h in enumerate(hidden_dims):\n",
    "        for j, p in enumerate(p_values):\n",
    "            # Filter by max_p if specified\n",
    "            if max_p is not None and p > max_p:\n",
    "                continue\n",
    "\n",
    "            exp_name = f\"k{k}_p{p}_h{h}\"\n",
    "            exp_dir = sweep_path / exp_name\n",
    "\n",
    "            if not exp_dir.exists():\n",
    "                continue\n",
    "\n",
    "            # Check if experiment is completed (has run_summary.yaml)\n",
    "            seed_dir = exp_dir / \"seed_0\"\n",
    "            if not seed_dir.exists() or not (seed_dir / \"run_summary.yaml\").exists():\n",
    "                continue  # Skip incomplete experiments\n",
    "\n",
    "            # Collect convergence steps from all seeds\n",
    "            convergence_steps = []\n",
    "            for seed_dir in exp_dir.glob(\"seed_*\"):\n",
    "                loss_file = seed_dir / \"train_loss_history.npy\"\n",
    "                if loss_file.exists():\n",
    "                    loss_history = np.load(loss_file)\n",
    "                    initial_loss = loss_history[0]\n",
    "\n",
    "                    if initial_loss > 0:\n",
    "                        # Compute reduction at each step\n",
    "                        reductions = 1 - loss_history / initial_loss\n",
    "\n",
    "                        # Find first step where reduction >= threshold\n",
    "                        converged_mask = reductions >= reduction_threshold\n",
    "                        if np.any(converged_mask):\n",
    "                            step = np.argmax(converged_mask)  # First True\n",
    "                            convergence_steps.append(step)\n",
    "                        # else: Never converged - don't add to list\n",
    "\n",
    "            if convergence_steps:\n",
    "                grid[i, j] = np.mean(convergence_steps)\n",
    "                std_grid[i, j] = (\n",
    "                    np.std(convergence_steps) if len(convergence_steps) > 1 else 0.0\n",
    "                )\n",
    "            # else: No seeds converged - grid[i,j] remains NaN (blacked out)\n",
    "\n",
    "    return grid, std_grid"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "bc6dd932"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_sweep_results_grid_final_loss_p_h(\n",
    "    sweep_dir: str,\n",
    "    k: int,\n",
    "    p_values: list,\n",
    "    hidden_dims: list,\n",
    "    max_p: int = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load sweep results and compute final training loss for p vs hidden_dim sweep.\n",
    "\n",
    "    Updated for experiment naming: k{k}_p{p}_h{h}\n",
    "    Only loads completed experiments (checks for run_summary.yaml).\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to the sweep directory\n",
    "        k: Sequence length parameter (2, 3, or 4)\n",
    "        p_values: List of p (group size) values\n",
    "        hidden_dims: List of hidden dimension values\n",
    "        max_p: Maximum p value to include (filters incomplete experiments)\n",
    "\n",
    "    Returns:\n",
    "        grid: 2D array with mean final training loss (NaN if experiment incomplete)\n",
    "              Shape: (len(hidden_dims), len(p_values))\n",
    "        std_grid: 2D array with standard deviations across seeds\n",
    "    \"\"\"\n",
    "    sweep_path = Path(sweep_dir)\n",
    "\n",
    "    grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "    std_grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "\n",
    "    for i, h in enumerate(hidden_dims):\n",
    "        for j, p in enumerate(p_values):\n",
    "            # Filter by max_p if specified\n",
    "            if max_p is not None and p > max_p:\n",
    "                continue\n",
    "\n",
    "            exp_name = f\"k{k}_p{p}_h{h}\"\n",
    "            exp_dir = sweep_path / exp_name\n",
    "\n",
    "            if not exp_dir.exists():\n",
    "                continue\n",
    "\n",
    "            # Check if experiment is completed (has run_summary.yaml)\n",
    "            seed_dir = exp_dir / \"seed_0\"\n",
    "            if not seed_dir.exists() or not (seed_dir / \"run_summary.yaml\").exists():\n",
    "                continue  # Skip incomplete experiments\n",
    "\n",
    "            # Collect final losses from all seeds\n",
    "            final_losses = []\n",
    "            for seed_dir in exp_dir.glob(\"seed_*\"):\n",
    "                loss_file = seed_dir / \"train_loss_history.npy\"\n",
    "                if loss_file.exists():\n",
    "                    loss_history = np.load(loss_file)\n",
    "                    if len(loss_history) > 0:\n",
    "                        final_loss = loss_history[-1]  # Last value\n",
    "                        final_losses.append(final_loss)\n",
    "\n",
    "            if final_losses:\n",
    "                grid[i, j] = np.mean(final_losses)\n",
    "                std_grid[i, j] = np.std(final_losses) if len(final_losses) > 1 else 0.0\n",
    "            # else: No seeds found - grid[i,j] remains NaN (blacked out)\n",
    "\n",
    "    return grid, std_grid"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "9a87f24d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_training_loss_curves_p(\n",
    "    sweep_dir: str,\n",
    "    k: int,\n",
    "    hidden_dim: int,\n",
    "    p_values: list,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load training loss histories for different group sizes (p) with fixed k and hidden_dim.\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to the sweep directory\n",
    "        k: Sequence length parameter (fixed)\n",
    "        hidden_dim: Hidden dimension (fixed)\n",
    "        p_values: List of p (group size) values to plot\n",
    "\n",
    "    Returns:\n",
    "        curves: Dictionary mapping p -> list of loss histories (one per seed)\n",
    "                Each loss history is a numpy array\n",
    "    \"\"\"\n",
    "    sweep_path = Path(sweep_dir)\n",
    "\n",
    "    curves = {}\n",
    "\n",
    "    for p in p_values:\n",
    "        exp_name = f\"k{k}_p{p}_h{hidden_dim}\"\n",
    "        exp_dir = sweep_path / exp_name\n",
    "\n",
    "        if not exp_dir.exists():\n",
    "            continue\n",
    "\n",
    "        # Check if experiment is completed\n",
    "        seed_dir = exp_dir / \"seed_0\"\n",
    "        if not seed_dir.exists() or not (seed_dir / \"run_summary.yaml\").exists():\n",
    "            continue  # Skip incomplete experiments\n",
    "\n",
    "        # Collect loss histories from all seeds\n",
    "        loss_histories = []\n",
    "        for seed_dir in exp_dir.glob(\"seed_*\"):\n",
    "            loss_file = seed_dir / \"train_loss_history.npy\"\n",
    "            if loss_file.exists():\n",
    "                loss_history = np.load(loss_file)\n",
    "                if len(loss_history) > 0:\n",
    "                    loss_histories.append(loss_history)\n",
    "\n",
    "        if loss_histories:\n",
    "            curves[p] = loss_histories\n",
    "\n",
    "    return curves"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "3bb53f80"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_sweep_results_grid_final_val_loss_p_h(\n",
    "    sweep_dir: str,\n",
    "    k: int,\n",
    "    p_values: list,\n",
    "    hidden_dims: list,\n",
    "    max_p: int = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load sweep results and compute final validation loss for p vs hidden_dim sweep.\n",
    "\n",
    "    Updated for experiment naming: k{k}_p{p}_h{h}\n",
    "    Only loads completed experiments (checks for run_summary.yaml).\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to the sweep directory\n",
    "        k: Sequence length parameter (2, 3, or 4)\n",
    "        p_values: List of p (group size) values\n",
    "        hidden_dims: List of hidden dimension values\n",
    "        max_p: Maximum p value to include (filters incomplete experiments)\n",
    "\n",
    "    Returns:\n",
    "        grid: 2D array with mean final validation loss (NaN if experiment incomplete)\n",
    "              Shape: (len(hidden_dims), len(p_values))\n",
    "        std_grid: 2D array with standard deviations across seeds\n",
    "    \"\"\"\n",
    "    sweep_path = Path(sweep_dir)\n",
    "\n",
    "    grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "    std_grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "\n",
    "    for i, h in enumerate(hidden_dims):\n",
    "        for j, p in enumerate(p_values):\n",
    "            # Filter by max_p if specified\n",
    "            if max_p is not None and p > max_p:\n",
    "                continue\n",
    "\n",
    "            exp_name = f\"k{k}_p{p}_h{h}\"\n",
    "            exp_dir = sweep_path / exp_name\n",
    "\n",
    "            if not exp_dir.exists():\n",
    "                continue\n",
    "\n",
    "            # Check if experiment is completed (has run_summary.yaml)\n",
    "            seed_dir = exp_dir / \"seed_0\"\n",
    "            if not seed_dir.exists() or not (seed_dir / \"run_summary.yaml\").exists():\n",
    "                continue  # Skip incomplete experiments\n",
    "\n",
    "            # Collect final validation losses from all seeds\n",
    "            final_losses = []\n",
    "            for seed_dir in exp_dir.glob(\"seed_*\"):\n",
    "                loss_file = seed_dir / \"val_loss_history.npy\"\n",
    "                if loss_file.exists():\n",
    "                    loss_history = np.load(loss_file)\n",
    "                    if len(loss_history) > 0:\n",
    "                        final_loss = loss_history[-1]  # Last value\n",
    "                        final_losses.append(final_loss)\n",
    "\n",
    "            if final_losses:\n",
    "                grid[i, j] = np.mean(final_losses)\n",
    "                std_grid[i, j] = np.std(final_losses) if len(final_losses) > 1 else 0.0\n",
    "            # else: No seeds found - grid[i,j] remains NaN (blacked out)\n",
    "\n",
    "    return grid, std_grid"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "bf14dee1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define parameter values from the sweep config\n",
    "# Filter to p <= 55 for completed experiments\n",
    "p_values = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "hidden_dims = [80, 160, 240, 320, 400, 480, 560, 640, 720, 800, 880, 960, 1040, 1120]\n",
    "k_values = [2, 3]  # , 4]  # Different k values to plot separately"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "42ce6ffd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot steps to convergence grid"
   ],
   "id": "7bf99dee"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load convergence data for each k value separately\n",
    "reduction_threshold = 0.90\n",
    "max_p = 70  # Only visualize completed experiments (p <= 55)\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Create separate plots for each k value\n",
    "for k in k_values:\n",
    "    conv_grid, conv_std = load_sweep_results_grid_convergence_p_h(\n",
    "        sweep_dir,\n",
    "        k,\n",
    "        p_values,\n",
    "        hidden_dims,\n",
    "        reduction_threshold=reduction_threshold,\n",
    "        max_p=max_p,\n",
    "    )\n",
    "\n",
    "    # Filter p values - only show p <= max_p\n",
    "    p_values_filtered = [p for p in p_values if p <= max_p]\n",
    "\n",
    "    # Plot convergence heatmap: p (group size) vs hidden_dim\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = plt.cm.viridis_r.copy()\n",
    "    cmap.set_bad(color=\"black\")\n",
    "    # Set extent to align cells with tick positions\n",
    "    # extent: [left, right, bottom, top] in data coordinates\n",
    "    plt.imshow(\n",
    "        conv_grid[:, : len(p_values_filtered)],\n",
    "        aspect=\"equal\",\n",
    "        cmap=cmap,\n",
    "        norm=LogNorm(),\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Group Size $|G|$\", fontsize=14)\n",
    "    plt.ylabel(\"Hidden Dimension $H$\", fontsize=14)\n",
    "    plt.xticks(\n",
    "        range(len(p_values_filtered)), p_values_filtered, rotation=45, ha=\"center\"\n",
    "    )\n",
    "\n",
    "    # Set y-axis ticks (hidden dimensions)\n",
    "    plt.yticks(range(len(hidden_dims)), hidden_dims)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    # Theory boundaries\n",
    "    x_step = np.arange(len(p_values_filtered) + 1) - 0.5\n",
    "\n",
    "    # Upper boundary: H = (k+1)*2^{k-1} * |G|\n",
    "    upper_boundary_coeff = (k + 1) * (2 ** (k - 1)) * reduction_threshold\n",
    "    y_step_upper = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                # Find the first H that satisfies H >= upper_boundary_coeff * p\n",
    "                np.argmax(np.array(hidden_dims) >= upper_boundary_coeff * p)\n",
    "                if upper_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_upper.append(y_step_upper[-1])  # Extend for step plot\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_upper = [y - 0.5 for y in y_step_upper]\n",
    "\n",
    "    # Lower boundary: H = 2^{k-1} * |G|\n",
    "    lower_boundary_coeff = 2 ** (k - 1) * reduction_threshold\n",
    "    y_step_lower = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                # Find the first H that satisfies H >= lower_boundary_coeff * p\n",
    "                np.argmax(np.array(hidden_dims) >= lower_boundary_coeff * p)\n",
    "                if lower_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_lower.append(y_step_lower[-1])  # Extend for step plot\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_lower = [y - 0.5 for y in y_step_lower]\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_upper,\n",
    "        where=\"post\",\n",
    "        color=\"red\",\n",
    "        linewidth=4,\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Upper boundary ($H$ = $(k+1) \\\\cdot 2^{{k-1}} |G| x {reduction_threshold}$ = {upper_boundary_coeff * reduction_threshold} * |G|) \",\n",
    "    )\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_lower,\n",
    "        where=\"post\",\n",
    "        color=\"white\",\n",
    "        linewidth=4,\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Lower boundary ($H$ = $2^{{k-1}} |G| x {reduction_threshold}$ = {lower_boundary_coeff * reduction_threshold} * |G|) \",\n",
    "    )\n",
    "\n",
    "    # Place legend outside the plot area\n",
    "    plt.legend(\n",
    "        loc=\"upper center\", bbox_to_anchor=(0.5, -0.12), fontsize=12, frameon=True\n",
    "    )\n",
    "\n",
    "    plt.colorbar(label=f\"Steps to {reduction_threshold*100}% Convergence\")\n",
    "    plt.title(\n",
    "        f\"Steps to {reduction_threshold*100}% Convergence: Group Size $|G|$ vs Hidden Dimension $H$\\n($k={k}$, black = did not converge, p \u2264 {max_p})\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "522570f5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Training Loss\n",
    "    "
   ],
   "id": "28e479df"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load final training loss data for each k value separately\n",
    "max_p = 70  # Only visualize completed experiments (p <= 55)\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Create separate plots for each k value\n",
    "for k in k_values:\n",
    "    loss_grid, loss_std = load_sweep_results_grid_final_loss_p_h(\n",
    "        sweep_dir,\n",
    "        k,\n",
    "        p_values,\n",
    "        hidden_dims,\n",
    "        max_p=max_p,\n",
    "    )\n",
    "\n",
    "    # Filter p values - only show p <= max_p\n",
    "    p_values_filtered = [p for p in p_values if p <= max_p]\n",
    "\n",
    "    # Plot final loss heatmap: p (group size) vs hidden_dim\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = plt.cm.viridis_r.copy()\n",
    "    cmap.set_bad(color=\"black\")\n",
    "    # Set extent to align cells with tick positions\n",
    "    # extent: [left, right, bottom, top] in data coordinates\n",
    "    plt.imshow(\n",
    "        loss_grid[:, : len(p_values_filtered)],\n",
    "        aspect=\"equal\",\n",
    "        cmap=cmap,\n",
    "        norm=LogNorm(),\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Group Size $|G|$\", fontsize=14)\n",
    "    plt.ylabel(\"Hidden Dimension $H$\", fontsize=14)\n",
    "    plt.xticks(\n",
    "        range(len(p_values_filtered)), p_values_filtered, rotation=45, ha=\"center\"\n",
    "    )\n",
    "\n",
    "    # Set y-axis ticks (hidden dimensions)\n",
    "    plt.yticks(range(len(hidden_dims)), hidden_dims)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    # Theory boundaries\n",
    "    x_step = np.arange(len(p_values_filtered) + 1) - 0.5\n",
    "\n",
    "    # Upper boundary: H = (k+1)*2^{k-1} * |G|\n",
    "    upper_boundary_coeff = (k + 1) * (2 ** (k - 1))\n",
    "    y_step_upper = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                # Find the first H that satisfies H >= upper_boundary_coeff * p\n",
    "                np.argmax(np.array(hidden_dims) >= upper_boundary_coeff * p)\n",
    "                if upper_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_upper.append(y_step_upper[-1])  # Extend for step plot\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_upper = [y - 0.5 for y in y_step_upper]\n",
    "\n",
    "    # Lower boundary: H = 2^{k-1} * |G|\n",
    "    lower_boundary_coeff = 2 ** (k - 1)\n",
    "    y_step_lower = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                # Find the first H that satisfies H >= lower_boundary_coeff * p\n",
    "                np.argmax(np.array(hidden_dims) >= lower_boundary_coeff * p)\n",
    "                if lower_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_lower.append(y_step_lower[-1])  # Extend for step plot\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_lower = [y - 0.5 for y in y_step_lower]\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_upper,\n",
    "        where=\"post\",\n",
    "        color=\"magenta\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Upper boundary ($H$ \u2265 $(k+1) \\\\cdot 2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_lower,\n",
    "        where=\"post\",\n",
    "        color=\"red\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Lower boundary ($H$ \u2265 $2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    # Place legend outside the plot area\n",
    "    plt.legend(\n",
    "        loc=\"upper center\", bbox_to_anchor=(0.5, -0.12), fontsize=12, frameon=True\n",
    "    )\n",
    "\n",
    "    plt.colorbar(label=\"Final Training Loss\")\n",
    "    plt.title(\n",
    "        f\"Final Training Loss: Group Size $|G|$ vs Hidden Dimension $H$\\n($k={k}$)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "06fb5f82"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loss Curves by Group Size\n"
   ],
   "id": "93d367cb"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot training loss curves for different group sizes\n",
    "# Specify the hidden dimension to use\n",
    "hidden_dim = 160  # Change this to plot different hidden dimensions\n",
    "\n",
    "# Use all available p values (or filter as needed)\n",
    "p_values_to_plot = [p for p in p_values if p <= 55]  # Adjust max_p as needed\n",
    "\n",
    "# Create separate plots for each k value\n",
    "for k in k_values:\n",
    "    # Load training loss curves for different p values\n",
    "    curves = load_training_loss_curves_p(\n",
    "        sweep_dir,\n",
    "        k,\n",
    "        hidden_dim,\n",
    "        p_values_to_plot,\n",
    "    )\n",
    "\n",
    "    if not curves:\n",
    "        print(f\"No data found for k={k}, H={hidden_dim}\")\n",
    "        continue\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Plot each group size as a separate curve\n",
    "    # Use a colormap to distinguish different p values\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(curves)))\n",
    "\n",
    "    for i, (p, loss_histories) in enumerate(sorted(curves.items())):\n",
    "        # Plot mean curve with shaded error bars\n",
    "        # Find the maximum length to align all curves\n",
    "        max_len = max(len(hist) for hist in loss_histories)\n",
    "\n",
    "        # Pad shorter histories with NaN or last value\n",
    "        aligned_histories = []\n",
    "        for hist in loss_histories:\n",
    "            if len(hist) < max_len:\n",
    "                padded = np.full(max_len, np.nan)\n",
    "                padded[: len(hist)] = hist\n",
    "                aligned_histories.append(padded)\n",
    "            else:\n",
    "                aligned_histories.append(hist)\n",
    "\n",
    "        aligned_histories = np.array(aligned_histories)\n",
    "\n",
    "        # Compute mean and std across seeds\n",
    "        mean_loss = np.nanmean(aligned_histories, axis=0)\n",
    "        std_loss = np.nanstd(aligned_histories, axis=0)\n",
    "\n",
    "        # Create step array (1-indexed for log scale)\n",
    "        steps = np.arange(1, len(mean_loss) + 1)\n",
    "\n",
    "        # Plot mean curve\n",
    "        plt.loglog(\n",
    "            steps,\n",
    "            mean_loss,\n",
    "            color=colors[i],\n",
    "            linewidth=2,\n",
    "            label=f\"$|G|={p}$\",\n",
    "        )\n",
    "\n",
    "        # Plot shaded error region (optional, can be commented out if too cluttered)\n",
    "        # plt.fill_between(\n",
    "        #     steps,\n",
    "        #     mean_loss - std_loss,\n",
    "        #     mean_loss + std_loss,\n",
    "        #     color=colors[i],\n",
    "        #     alpha=0.2,\n",
    "        # )\n",
    "\n",
    "    plt.xlabel(\"Training Steps\", fontsize=14)\n",
    "    plt.ylabel(\"Training Loss\", fontsize=14)\n",
    "    plt.title(\n",
    "        f\"Training Loss Curves: Group Size $|G|$ vs Steps\\n($k={k}$, $H={hidden_dim}$)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.legend(loc=\"best\", fontsize=10, ncol=2)\n",
    "    plt.grid(True, alpha=0.3, which=\"both\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "5ed8f9c0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load final validation loss data for each k value separately\n",
    "max_p = 60  # Only visualize completed experiments (p <= 55)\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Create separate plots for each k value\n",
    "for k in k_values:\n",
    "    loss_grid, loss_std = load_sweep_results_grid_final_val_loss_p_h(\n",
    "        sweep_dir,\n",
    "        k,\n",
    "        p_values,\n",
    "        hidden_dims,\n",
    "        max_p=max_p,\n",
    "    )\n",
    "\n",
    "    # Filter p values - only show p <= max_p\n",
    "    p_values_filtered = [p for p in p_values if p <= max_p]\n",
    "\n",
    "    # Plot final validation loss heatmap: p (group size) vs hidden_dim\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    cmap = plt.cm.viridis_r.copy()\n",
    "    cmap.set_bad(color=\"black\")\n",
    "    # Set extent to align cells with tick positions\n",
    "    # extent: [left, right, bottom, top] in data coordinates\n",
    "    plt.imshow(\n",
    "        loss_grid[:, : len(p_values_filtered)],\n",
    "        aspect=\"equal\",\n",
    "        cmap=cmap,\n",
    "        norm=LogNorm(),\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Group Size $|G|$\", fontsize=14)\n",
    "    plt.ylabel(\"Hidden Dimension $H$\", fontsize=14)\n",
    "    plt.xticks(\n",
    "        range(len(p_values_filtered)), p_values_filtered, rotation=45, ha=\"center\"\n",
    "    )\n",
    "\n",
    "    # Set y-axis ticks (hidden dimensions)\n",
    "    plt.yticks(range(len(hidden_dims)), hidden_dims)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    # Theory boundaries\n",
    "    x_step = np.arange(len(p_values_filtered) + 1) - 0.5\n",
    "\n",
    "    # Upper boundary: H = (k+1)*2^{k-1} * |G|\n",
    "    upper_boundary_coeff = (k + 1) * (2 ** (k - 1))\n",
    "    y_step_upper = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                # Find the first H that satisfies H >= upper_boundary_coeff * p\n",
    "                np.argmax(np.array(hidden_dims) >= upper_boundary_coeff * p)\n",
    "                if upper_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_upper.append(y_step_upper[-1])  # Extend for step plot\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_upper = [y - 0.5 for y in y_step_upper]\n",
    "\n",
    "    # Lower boundary: H = 2^{k-1} * |G|\n",
    "    lower_boundary_coeff = 2 ** (k - 1)\n",
    "    y_step_lower = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                # Find the first H that satisfies H >= lower_boundary_coeff * p\n",
    "                np.argmax(np.array(hidden_dims) >= lower_boundary_coeff * p)\n",
    "                if lower_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_lower.append(y_step_lower[-1])  # Extend for step plot\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_lower = [y - 0.5 for y in y_step_lower]\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_upper,\n",
    "        where=\"post\",\n",
    "        color=\"red\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Upper boundary ($H$ \u2265 $(k+1) \\\\cdot 2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_lower,\n",
    "        where=\"post\",\n",
    "        color=\"blue\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Lower boundary ($H$ \u2265 $2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    # Place legend outside the plot area\n",
    "    plt.legend(\n",
    "        loc=\"upper center\", bbox_to_anchor=(0.5, -0.12), fontsize=12, frameon=True\n",
    "    )\n",
    "\n",
    "    plt.colorbar(label=\"Final Validation Loss\")\n",
    "    plt.title(\n",
    "        f\"Final Validation Loss: Group Size $|G|$ vs Hidden Dimension $H$\\n($k={k}$, black = incomplete experiment, p \u2264 {max_p})\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "96be1620"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Instability"
   ],
   "id": "d3111eeb"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_sweep_results_grid_spikiness_p_h(\n",
    "    sweep_dir: str, k: int, p_values: list, hidden_dims: list, max_p: int = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute fraction of training steps where loss increased (instability) for p vs h sweeps.\n",
    "\n",
    "    Updated for experiment naming: k{k}_p{p}_h{h}\n",
    "    Only loads completed experiments (checks for run_summary.yaml).\n",
    "\n",
    "    Args:\n",
    "        sweep_dir: Path to the sweep directory\n",
    "        k: Sequence length parameter (2, 3, or 4)\n",
    "        p_values: List of p (group size) values\n",
    "        hidden_dims: List of hidden dimension values\n",
    "        max_p: Maximum p value to include (filters incomplete experiments)\n",
    "\n",
    "    Returns:\n",
    "        grid: 2D array with mean frac_upward across seeds\n",
    "              Shape: (len(hidden_dims), len(p_values))\n",
    "        std_grid: 2D array with standard deviations\n",
    "    \"\"\"\n",
    "    sweep_path = Path(sweep_dir)\n",
    "\n",
    "    grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "    std_grid = np.full((len(hidden_dims), len(p_values)), np.nan)\n",
    "\n",
    "    for i, h in enumerate(hidden_dims):\n",
    "        for j, p in enumerate(p_values):\n",
    "            # Filter by max_p if specified\n",
    "            if max_p is not None and p > max_p:\n",
    "                continue\n",
    "\n",
    "            exp_name = f\"k{k}_p{p}_h{h}\"\n",
    "            exp_dir = sweep_path / exp_name\n",
    "\n",
    "            if not exp_dir.exists():\n",
    "                continue\n",
    "\n",
    "            # Check if experiment is completed\n",
    "            seed_dir = exp_dir / \"seed_0\"\n",
    "            if not seed_dir.exists() or not (seed_dir / \"run_summary.yaml\").exists():\n",
    "                continue  # Skip incomplete experiments\n",
    "\n",
    "            frac_upwards = []\n",
    "            for seed_dir in exp_dir.glob(\"seed_*\"):\n",
    "                loss_file = seed_dir / \"train_loss_history.npy\"\n",
    "                if loss_file.exists():\n",
    "                    loss_history = np.load(loss_file)\n",
    "                    log_loss = np.log10(loss_history + 1e-10)\n",
    "                    log_changes = np.diff(log_loss)\n",
    "\n",
    "                    # Fraction of steps where loss went UP\n",
    "                    frac_upward = np.sum(log_changes > 0) / len(log_changes)\n",
    "                    frac_upwards.append(frac_upward)\n",
    "\n",
    "            if frac_upwards:\n",
    "                grid[i, j] = np.mean(frac_upwards)\n",
    "                std_grid[i, j] = np.std(frac_upwards) if len(frac_upwards) > 1 else 0.0\n",
    "\n",
    "    return grid, std_grid"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "d743a392"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load spikiness data for each k value separately\n",
    "max_p = 70  # Only visualize completed experiments\n",
    "\n",
    "# Create separate plots for each k value\n",
    "for k in k_values:\n",
    "    spike_grid_p, spike_std_p = load_sweep_results_grid_spikiness_p_h(\n",
    "        sweep_dir, k, p_values, hidden_dims, max_p=max_p\n",
    "    )\n",
    "\n",
    "    p_values_filtered = [p for p in p_values if p <= max_p]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Set extent to align cells with tick positions\n",
    "    plt.imshow(\n",
    "        spike_grid_p[:, : len(p_values_filtered)],\n",
    "        aspect=\"equal\",\n",
    "        cmap=\"plasma\",\n",
    "        extent=[-0.5, len(p_values_filtered) - 0.5, len(hidden_dims) - 0.5, -0.5],\n",
    "    )\n",
    "    plt.xlabel(\"Group Size $|G|$\", fontsize=14)\n",
    "    plt.ylabel(\"Hidden Dimension $H$\", fontsize=14)\n",
    "    plt.xticks(\n",
    "        range(len(p_values_filtered)), p_values_filtered, rotation=45, ha=\"center\"\n",
    "    )\n",
    "    plt.yticks(range(len(hidden_dims)), hidden_dims)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    # Theory boundaries\n",
    "    x_step = np.arange(len(p_values_filtered) + 1) - 0.5\n",
    "\n",
    "    # Upper boundary: H = (k+1)*2^{k-1} * |G|\n",
    "    upper_boundary_coeff = (k + 1) * (2 ** (k - 1))\n",
    "    y_step_upper = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                np.argmax(np.array(hidden_dims) >= upper_boundary_coeff * p)\n",
    "                if upper_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_upper.append(y_step_upper[-1])\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_upper = [y - 0.5 for y in y_step_upper]\n",
    "\n",
    "    # Lower boundary: H = 2^{k-1} * |G|\n",
    "    lower_boundary_coeff = 2 ** (k - 1)\n",
    "    y_step_lower = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                np.argmax(np.array(hidden_dims) >= lower_boundary_coeff * p)\n",
    "                if lower_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_lower.append(y_step_lower[-1])\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_lower = [y - 0.5 for y in y_step_lower]\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_upper,\n",
    "        where=\"post\",\n",
    "        color=\"red\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Upper boundary ($H$ = $(k+1) \\\\cdot 2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_lower,\n",
    "        where=\"post\",\n",
    "        color=\"white\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Lower boundary ($H$ = $2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    plt.legend(\n",
    "        loc=\"upper center\", bbox_to_anchor=(0.5, -0.12), fontsize=12, frameon=True\n",
    "    )\n",
    "\n",
    "    plt.colorbar(label=\"Fraction of Upward Steps (Spikiness)\")\n",
    "    plt.title(\n",
    "        f\"Training Instability: Group Size $|G|$ vs Hidden Dimension $H$\\n($k={k}$)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "683b555c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load both metrics for each k value separately\n",
    "reduction_threshold = 0.99\n",
    "spikiness_threshold = 0.1\n",
    "max_p = 55  # Only visualize completed experiments\n",
    "\n",
    "# Create separate plots for each k value\n",
    "for k in k_values:\n",
    "    conv_grid_p, conv_std_p = load_sweep_results_grid_convergence_p_h(\n",
    "        sweep_dir, k, p_values, hidden_dims, \n",
    "        reduction_threshold=reduction_threshold,\n",
    "        max_p=max_p\n",
    "    )\n",
    "    spike_grid_p, spike_std_p = load_sweep_results_grid_spikiness_p_h(\n",
    "        sweep_dir, k, p_values, hidden_dims, max_p=max_p\n",
    "    )\n",
    "    \n",
    "    p_values_filtered = [p for p in p_values if p <= max_p]\n",
    "\n",
    "    # Create categorical grid: 0=black (no conv), 1=purple (spiky), 2=yellow (smooth)\n",
    "    category_grid = np.full((len(hidden_dims), len(p_values_filtered)), 0.0)  # Start with 0 (black)\n",
    "\n",
    "    for i in range(len(hidden_dims)):\n",
    "        for j in range(len(p_values_filtered)):\n",
    "            converged = not np.isnan(conv_grid_p[i, j])\n",
    "\n",
    "            if converged:\n",
    "                spiky = spike_grid_p[i, j] > spikiness_threshold\n",
    "                if spiky:\n",
    "                    category_grid[i, j] = 1.0  # Purple (spiky)\n",
    "                else:\n",
    "                    category_grid[i, j] = 2.0  # Yellow (smooth)\n",
    "            # else stays 0.0 (black, did not converge)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Custom colormap: black -> purple -> yellow\n",
    "    from matplotlib.colors import ListedColormap\n",
    "\n",
    "    colors = [\"black\", \"purple\", \"yellow\"]\n",
    "    cmap = ListedColormap(colors)\n",
    "\n",
    "    # Set extent to align cells with tick positions\n",
    "    im = ax.imshow(\n",
    "        category_grid, \n",
    "        aspect=\"auto\", \n",
    "        cmap=cmap, \n",
    "        vmin=0, \n",
    "        vmax=2,\n",
    "        extent=[-0.5, len(p_values_filtered) - 0.5, len(hidden_dims) - 0.5, -0.5]\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Group Size $|G|$\", fontsize=14)\n",
    "    ax.set_ylabel(\"Hidden Dimension $H$\", fontsize=14)\n",
    "\n",
    "    # Set x-axis ticks (p values)\n",
    "    ax.set_xticks(range(len(p_values_filtered)))\n",
    "    ax.set_xticklabels(p_values_filtered, rotation=45, ha=\"center\")\n",
    "\n",
    "    # Set y-axis ticks (hidden dimensions)\n",
    "    ax.set_yticks(range(len(hidden_dims)))\n",
    "    ax.set_yticklabels(hidden_dims)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Theory boundaries\n",
    "    x_step = np.arange(len(p_values_filtered) + 1) - 0.5\n",
    "    \n",
    "    # Upper boundary: H = (k+1)*2^{k-1} * |G|\n",
    "    upper_boundary_coeff = (k + 1) * (2 ** (k - 1))\n",
    "    y_step_upper = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                np.argmax(np.array(hidden_dims) >= upper_boundary_coeff * p)\n",
    "                if upper_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_upper.append(y_step_upper[-1])\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_upper = [y - 0.5 for y in y_step_upper]\n",
    "\n",
    "    # Lower boundary: H = 2^{k-1} * |G|\n",
    "    lower_boundary_coeff = 2 ** (k - 1)\n",
    "    y_step_lower = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                np.argmax(np.array(hidden_dims) >= lower_boundary_coeff * p)\n",
    "                if lower_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_lower.append(y_step_lower[-1])\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_lower = [y - 0.5 for y in y_step_lower]\n",
    "\n",
    "    ax.step(\n",
    "        x_step,\n",
    "        y_step_upper,\n",
    "        where=\"post\",\n",
    "        color=\"red\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Upper boundary ($H$ \u2265 $(k+1) \\\\cdot 2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "    \n",
    "    ax.step(\n",
    "        x_step,\n",
    "        y_step_lower,\n",
    "        where=\"post\",\n",
    "        color=\"blue\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Lower boundary ($H$ \u2265 $2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    # Create custom legend\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=\"black\", label=\"Did not converge\"),\n",
    "        Patch(facecolor=\"purple\", label=f\"Spiky (frac_up > {spikiness_threshold})\"),\n",
    "        Patch(facecolor=\"yellow\", label=\"Smooth convergence\"),\n",
    "        plt.Line2D([0], [0], color=\"r\", linewidth=3, linestyle=\"--\", label=f\"Upper boundary ($H$ \u2265 $(k+1) \\\\cdot 2^{{k-1}} |G|$)\"),\n",
    "        plt.Line2D([0], [0], color=\"b\", linewidth=3, linestyle=\"--\", label=f\"Lower boundary ($H$ \u2265 $2^{{k-1}} |G|$)\"),\n",
    "    ]\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc=\"upper left\", fontsize=11, frameon=True)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Convergence & Spikiness: $|G|$ vs $H$ ($k={k}$)\\nThresholds: {reduction_threshold*100}% convergence, {spikiness_threshold} spikiness (p \u2264 {max_p})\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "772517ad"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load both convergence and spikiness data for each k value separately\n",
    "reduction_threshold = 0.99\n",
    "max_p = 55  # Only visualize completed experiments\n",
    "\n",
    "# Create separate plots for each k value\n",
    "for k in k_values:\n",
    "    conv_grid_p, conv_std_p = load_sweep_results_grid_convergence_p_h(\n",
    "        sweep_dir,\n",
    "        k,\n",
    "        p_values,\n",
    "        hidden_dims,\n",
    "        reduction_threshold=reduction_threshold,\n",
    "        max_p=max_p,\n",
    "    )\n",
    "    spike_grid_p, spike_std_p = load_sweep_results_grid_spikiness_p_h(\n",
    "        sweep_dir, k, p_values, hidden_dims, max_p=max_p\n",
    "    )\n",
    "\n",
    "    p_values_filtered = [p for p in p_values if p <= max_p]\n",
    "\n",
    "    # Mask spikiness grid: only show spikiness for converged runs\n",
    "    spike_grid_masked = spike_grid_p.copy()\n",
    "    for i in range(len(hidden_dims)):\n",
    "        for j in range(len(p_values_filtered)):\n",
    "            if np.isnan(conv_grid_p[i, j]):\n",
    "                # Did not converge - set to NaN (will be black)\n",
    "                spike_grid_masked[i, j] = np.nan\n",
    "\n",
    "    # Plot with masked spikiness\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Use colormap with black for NaN\n",
    "    cmap_spike = plt.cm.plasma.copy()\n",
    "    cmap_spike.set_bad(color=\"black\")\n",
    "\n",
    "    # Set extent to align cells with tick positions\n",
    "    plt.imshow(\n",
    "        spike_grid_masked[:, : len(p_values_filtered)],\n",
    "        aspect=\"auto\",\n",
    "        cmap=cmap_spike,\n",
    "        vmin=0,\n",
    "        vmax=0.5,\n",
    "        extent=[-0.5, len(p_values_filtered) - 0.5, len(hidden_dims) - 0.5, -0.5],\n",
    "    )\n",
    "    plt.xlabel(\"Group Size $|G|$\", fontsize=14)\n",
    "    plt.ylabel(\"Hidden Dimension $H$\", fontsize=14)\n",
    "    plt.xticks(\n",
    "        range(len(p_values_filtered)), p_values_filtered, rotation=45, ha=\"center\"\n",
    "    )\n",
    "    plt.yticks(range(len(hidden_dims)), hidden_dims)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    # Theory boundaries\n",
    "    x_step = np.arange(len(p_values_filtered) + 1) - 0.5\n",
    "\n",
    "    # Upper boundary: H = (k+1)*2^{k-1} * |G|\n",
    "    upper_boundary_coeff = (k + 1) * (2 ** (k - 1))\n",
    "    y_step_upper = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                np.argmax(np.array(hidden_dims) >= upper_boundary_coeff * p)\n",
    "                if upper_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_upper.append(y_step_upper[-1])\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_upper = [y - 0.5 for y in y_step_upper]\n",
    "\n",
    "    # Lower boundary: H = 2^{k-1} * |G|\n",
    "    lower_boundary_coeff = 2 ** (k - 1)\n",
    "    y_step_lower = [\n",
    "        min(\n",
    "            len(hidden_dims) - 1,\n",
    "            (\n",
    "                np.argmax(np.array(hidden_dims) >= lower_boundary_coeff * p)\n",
    "                if lower_boundary_coeff * p <= max(hidden_dims)\n",
    "                else len(hidden_dims) - 1\n",
    "            ),\n",
    "        )\n",
    "        for p in p_values_filtered\n",
    "    ]\n",
    "    y_step_lower.append(y_step_lower[-1])\n",
    "    # Convert to edge positions (subtract 0.5 to place at bottom edge of cells)\n",
    "    y_step_lower = [y - 0.5 for y in y_step_lower]\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_upper,\n",
    "        where=\"post\",\n",
    "        color=\"red\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Upper boundary ($H$ \u2265 $(k+1) \\\\cdot 2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    plt.step(\n",
    "        x_step,\n",
    "        y_step_lower,\n",
    "        where=\"post\",\n",
    "        color=\"blue\",\n",
    "        linewidth=3,\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Lower boundary ($H$ \u2265 $2^{{k-1}} |G|$)\",\n",
    "    )\n",
    "\n",
    "    # Custom legend\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=\"black\", label=\"Did not converge\"),\n",
    "        Patch(facecolor=\"purple\", label=\"Low spikiness (~0)\"),\n",
    "        Patch(facecolor=\"yellow\", label=\"High spikiness (~0.5)\"),\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            color=\"red\",\n",
    "            linewidth=3,\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Upper boundary ($H$ \u2265 $(k+1) \\\\cdot 2^{{k-1}} |G|$)\",\n",
    "        ),\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            color=\"white\",\n",
    "            linewidth=3,\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Lower boundary ($H$ \u2265 $2^{{k-1}} |G|$)\",\n",
    "        ),\n",
    "    ]\n",
    "    plt.legend(\n",
    "        handles=legend_elements,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.12),\n",
    "        fontsize=11,\n",
    "        frameon=True,\n",
    "        ncol=5,\n",
    "    )\n",
    "\n",
    "    plt.colorbar(label=\"Fraction of Upward Steps (Spikiness)\")\n",
    "    plt.title(\n",
    "        f\"Training Instability: Group Size $|G|$ vs Hidden Dimension $H$\\n($k={k}$, black = did not converge, p \u2264 {max_p})\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "53ed6f4f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": [],
   "id": "3f30eb24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gagf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}